{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "PythonData",
      "language": "python",
      "name": "pythondata"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Copy of  AlphabetSoupCharity_Optimized.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jacquie0583/Neural_Network_Charity_Analysis/blob/main/AlphabetSoupCharity_Optimized.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5lNOX2UgjvD"
      },
      "source": [
        "### Deliverable 3: Optimizing the Data for a Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "5grooL69gjvG",
        "outputId": "311235d5-2965-48cb-944c-c173b7aad0d1"
      },
      "source": [
        "# Import our dependencies\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "# Import checkpoint dependencies\n",
        "import os\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "#  Import and read the charity_data.csv.\n",
        "import pandas as pd \n",
        "df_application = pd.read_csv(\"charity_data.csv\")\n",
        "df_application.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EIN</th>\n",
              "      <th>NAME</th>\n",
              "      <th>APPLICATION_TYPE</th>\n",
              "      <th>AFFILIATION</th>\n",
              "      <th>CLASSIFICATION</th>\n",
              "      <th>USE_CASE</th>\n",
              "      <th>ORGANIZATION</th>\n",
              "      <th>STATUS</th>\n",
              "      <th>INCOME_AMT</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10520599</td>\n",
              "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
              "      <td>T10</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10531628</td>\n",
              "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Co-operative</td>\n",
              "      <td>1</td>\n",
              "      <td>1-9999</td>\n",
              "      <td>N</td>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10547893</td>\n",
              "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
              "      <td>T5</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C3000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10553066</td>\n",
              "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
              "      <td>T3</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>10000-24999</td>\n",
              "      <td>N</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10556103</td>\n",
              "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>Heathcare</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>100000-499999</td>\n",
              "      <td>N</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        EIN                                      NAME  ... ASK_AMT IS_SUCCESSFUL\n",
              "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB  ...    5000             1\n",
              "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR  ...  108590             1\n",
              "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS  ...    5000             0\n",
              "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION  ...    6692             1\n",
              "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT  ...  142590             1\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlk9Zm9kgjvI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "bdef79be-ff36-4002-ac45-9b03b2e0cc25"
      },
      "source": [
        "# Drop the non-beneficial ID columns, 'EIN' only \n",
        "df_application.drop(columns=[\"EIN\"], inplace=True)\n",
        "df_application.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NAME</th>\n",
              "      <th>APPLICATION_TYPE</th>\n",
              "      <th>AFFILIATION</th>\n",
              "      <th>CLASSIFICATION</th>\n",
              "      <th>USE_CASE</th>\n",
              "      <th>ORGANIZATION</th>\n",
              "      <th>STATUS</th>\n",
              "      <th>INCOME_AMT</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
              "      <td>T10</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Co-operative</td>\n",
              "      <td>1</td>\n",
              "      <td>1-9999</td>\n",
              "      <td>N</td>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
              "      <td>T5</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C3000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
              "      <td>T3</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>10000-24999</td>\n",
              "      <td>N</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>Heathcare</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>100000-499999</td>\n",
              "      <td>N</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       NAME  ... IS_SUCCESSFUL\n",
              "0              BLUE KNIGHTS MOTORCYCLE CLUB  ...             1\n",
              "1    AMERICAN CHESAPEAKE CLUB CHARITABLE TR  ...             1\n",
              "2        ST CLOUD PROFESSIONAL FIREFIGHTERS  ...             0\n",
              "3            SOUTHSIDE ATHLETIC ASSOCIATION  ...             1\n",
              "4  GENETIC RESEARCH INSTITUTE OF THE DESERT  ...             1\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzv8WnjMgjvI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da32d6ca-4b1d-4145-abcd-8f00df266455"
      },
      "source": [
        "# Determine the number of unique values in each column.\n",
        "n = df_application.nunique(axis=0)\n",
        "\n",
        "print(\"no.of.unique values in each column :\\n\",\n",
        "       n)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no.of.unique values in each column :\n",
            " NAME                      19568\n",
            "APPLICATION_TYPE             17\n",
            "AFFILIATION                   6\n",
            "CLASSIFICATION               71\n",
            "USE_CASE                      5\n",
            "ORGANIZATION                  4\n",
            "STATUS                        2\n",
            "INCOME_AMT                    9\n",
            "SPECIAL_CONSIDERATIONS        2\n",
            "ASK_AMT                    8747\n",
            "IS_SUCCESSFUL                 2\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAXphsoygjvJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cebcb1c0-4713-4a18-9f25-0c1abd2a640e"
      },
      "source": [
        "# Look at APPLICATION_TYPE value counts for binning\n",
        "df_application.APPLICATION_TYPE.value_counts()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T3     27037\n",
              "T4      1542\n",
              "T6      1216\n",
              "T5      1173\n",
              "T19     1065\n",
              "T8       737\n",
              "T7       725\n",
              "T10      528\n",
              "T9       156\n",
              "T13       66\n",
              "T12       27\n",
              "T2        16\n",
              "T25        3\n",
              "T14        3\n",
              "T29        2\n",
              "T15        2\n",
              "T17        1\n",
              "Name: APPLICATION_TYPE, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aq84wCIpgjvJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "b4e28bf9-2006-44d3-a401-17f362f1b965"
      },
      "source": [
        "# Visualize the value counts of APPLICATION_TYPE\n",
        "#  YOUR CODE GOES HERE\n",
        "df_AP = df_application.APPLICATION_TYPE.value_counts()\n",
        "df_AP.plot.density()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0be5deaa10>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2VKAbJwSzZz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41e9ae1e-d4cf-44d9-818c-450dbc1baf3d"
      },
      "source": [
        "# Determine which values to replace if counts are less than ...?\n",
        "replace_application = list(df_AP[df_AP < 200].index)\n",
        "\n",
        "# Replace in dataframe\n",
        "for app in replace_application:\n",
        "    df_application.APPLICATION_TYPE = df_application.APPLICATION_TYPE.replace(app,\"Other\")\n",
        "    \n",
        "# Check to make sure binning was successful\n",
        "df_application.APPLICATION_TYPE.value_counts()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T3       27037\n",
              "T4        1542\n",
              "T6        1216\n",
              "T5        1173\n",
              "T19       1065\n",
              "T8         737\n",
              "T7         725\n",
              "T10        528\n",
              "Other      276\n",
              "Name: APPLICATION_TYPE, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDEjgPRHgjvK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73ff5734-ca84-4f13-85ec-75c26e232c7f"
      },
      "source": [
        "# Look at CLASSIFICATION value counts for binning\n",
        "df_application.CLASSIFICATION.value_counts()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "C1000    17326\n",
              "C2000     6074\n",
              "C1200     4837\n",
              "C3000     1918\n",
              "C2100     1883\n",
              "         ...  \n",
              "C1370        1\n",
              "C2600        1\n",
              "C4200        1\n",
              "C1248        1\n",
              "C1728        1\n",
              "Name: CLASSIFICATION, Length: 71, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wts4iWj-gjvL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "106b6994-1cc3-4538-a1b0-9e6d5cebe3df"
      },
      "source": [
        "# Visualize the value counts of CLASSIFICATION\n",
        "df_Class = df_application.CLASSIFICATION.value_counts()\n",
        "df_Class.plot.density()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0be38cae90>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCfNG7OYgjvL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3430aae9-9321-4ac0-e07e-eb759c6264d9"
      },
      "source": [
        "# Determine which values to replace if counts are less than ..?\n",
        "#  YOUR CODE GOES HERE\n",
        "replace_class = list(df_Class[df_Class < 1000].index)\n",
        " \n",
        "# Replace in dataframe\n",
        "for cls in replace_class:\n",
        "    df_application.CLASSIFICATION= df_application.CLASSIFICATION.replace(cls,\"Other\")\n",
        "    \n",
        "# Check to make sure binning was successful\n",
        "df_application.CLASSIFICATION.value_counts()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "C1000    17326\n",
              "C2000     6074\n",
              "C1200     4837\n",
              "Other     2261\n",
              "C3000     1918\n",
              "C2100     1883\n",
              "Name: CLASSIFICATION, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKG3N_p45gVc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40277bd8-4da0-4169-e348-28316522aedb"
      },
      "source": [
        "df_application.dtypes"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NAME                      object\n",
              "APPLICATION_TYPE          object\n",
              "AFFILIATION               object\n",
              "CLASSIFICATION            object\n",
              "USE_CASE                  object\n",
              "ORGANIZATION              object\n",
              "STATUS                     int64\n",
              "INCOME_AMT                object\n",
              "SPECIAL_CONSIDERATIONS    object\n",
              "ASK_AMT                    int64\n",
              "IS_SUCCESSFUL              int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLg9Mx8-t0ZU"
      },
      "source": [
        "#Change datatypes ASK_AMT\n",
        "df_application['ASK_AMT'] = df_application['ASK_AMT'].astype(str)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6cxUENSt0iT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9af358e5-8c9e-4f49-ee5d-627c138d90a2"
      },
      "source": [
        "df_application.dtypes"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NAME                      object\n",
              "APPLICATION_TYPE          object\n",
              "AFFILIATION               object\n",
              "CLASSIFICATION            object\n",
              "USE_CASE                  object\n",
              "ORGANIZATION              object\n",
              "STATUS                     int64\n",
              "INCOME_AMT                object\n",
              "SPECIAL_CONSIDERATIONS    object\n",
              "ASK_AMT                   object\n",
              "IS_SUCCESSFUL              int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_Wap7eit0nZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea619261-e66e-4c18-c3e9-ae760e6c2a9d"
      },
      "source": [
        "# Look at APPLICATION_TYPE value counts for binning\n",
        "df_application.APPLICATION_TYPE.value_counts()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T3       27037\n",
              "T4        1542\n",
              "T6        1216\n",
              "T5        1173\n",
              "T19       1065\n",
              "T8         737\n",
              "T7         725\n",
              "T10        528\n",
              "Other      276\n",
              "Name: APPLICATION_TYPE, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_s-A6tPt0rv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "ec8fd379-7b6f-42db-9ebf-397283978168"
      },
      "source": [
        "# Visualize the value counts of APPLICATION_TYPE\n",
        "Ap = df_application.APPLICATION_TYPE.value_counts()\n",
        "Ap.plot.density()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0be3359fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86S-0yYPt0xQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad78892e-1192-4f36-f1b2-8d57917a0ee9"
      },
      "source": [
        "# Determine which values to replace if counts are less than ...?\n",
        "replace_application = list(Ap[Ap < 200].index)\n",
        "\n",
        "# Replace in dataframe\n",
        "for app in replace_application:\n",
        "   df_application.APPLICATION_TYPE = df_application.APPLICATION_TYPE.replace(app,\"Other\")\n",
        "    \n",
        "# Check to make sure binning was successful\n",
        "df_application.APPLICATION_TYPE.value_counts()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T3       27037\n",
              "T4        1542\n",
              "T6        1216\n",
              "T5        1173\n",
              "T19       1065\n",
              "T8         737\n",
              "T7         725\n",
              "T10        528\n",
              "Other      276\n",
              "Name: APPLICATION_TYPE, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNo5XPOsuWjj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a57ab3e1-ef41-45a4-9b14-659726b31a25"
      },
      "source": [
        "# Look at CLASSIFICATION value counts for binning\n",
        "df_application.CLASSIFICATION.value_counts()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "C1000    17326\n",
              "C2000     6074\n",
              "C1200     4837\n",
              "Other     2261\n",
              "C3000     1918\n",
              "C2100     1883\n",
              "Name: CLASSIFICATION, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4xAI0I6uWpS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "c72838f3-915f-4ae9-8fef-633081ddb877"
      },
      "source": [
        "# Visualize the value counts of CLASSIFICATION\n",
        "cla = df_application.CLASSIFICATION.value_counts()\n",
        "cla.plot.density()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0be3342bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDeblqfguWtC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6791dab-b907-4c61-c36a-9f75c2b60378"
      },
      "source": [
        "# Determine which values to replace if counts are less than ..?\n",
        "replace_class = list(cla[cla < 300].index)\n",
        "\n",
        "# Replace in dataframe\n",
        "for cls in replace_class:\n",
        "    df_application.CLASSIFICATION = df_application.CLASSIFICATION.replace(cls,\"Other\")\n",
        "    \n",
        "# Check to make sure binning was successful\n",
        "df_application.CLASSIFICATION.value_counts()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "C1000    17326\n",
              "C2000     6074\n",
              "C1200     4837\n",
              "Other     2261\n",
              "C3000     1918\n",
              "C2100     1883\n",
              "Name: CLASSIFICATION, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkBlFCUNuWwu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d438206c-d20a-49f7-8949-37d9ff26667d"
      },
      "source": [
        "# Look at NAME value counts for binning\n",
        "df_application.NAME.value_counts()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PARENT BOOSTER USA INC                                          1260\n",
              "TOPS CLUB INC                                                    765\n",
              "UNITED STATES BOWLING CONGRESS INC                               700\n",
              "WASHINGTON STATE UNIVERSITY                                      492\n",
              "AMATEUR ATHLETIC UNION OF THE UNITED STATES INC                  408\n",
              "                                                                ... \n",
              "LANGUAGE AND CULTURE TRAINING CENTER                               1\n",
              "INTERNATIONAL SUBMARINERS ASSOCIATION-USA                          1\n",
              "ATHCON INC                                                         1\n",
              "FORCED EXOTIC ANIMAL RELOCATION AND CENTER FOR EDUCATION INC       1\n",
              "ANIMAL RESCUE OF FRESNO                                            1\n",
              "Name: NAME, Length: 19568, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PB-MpdrauW0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "aa3fe7a2-7c10-46b7-f1d8-d8e29a8e154f"
      },
      "source": [
        "# Visualize the value counts of NAME\n",
        "name = df_application.NAME.value_counts()\n",
        "name.plot.density()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0be329ab90>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zF0n1c6wuW3l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e9df218-3ecc-4005-bb4b-b946905b2a09"
      },
      "source": [
        "# Determine which values to replace if counts are less than ...?\n",
        "replace_name = list(name[name < 50].index)\n",
        "\n",
        "# Replace in dataframe\n",
        "for app in replace_name:\n",
        "    df_application.NAME = df_application.NAME.replace(app,\"Other\")\n",
        "    \n",
        "# Check to make sure binning was successful\n",
        "df_application.NAME.value_counts()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Other                                                                 24545\n",
              "PARENT BOOSTER USA INC                                                 1260\n",
              "TOPS CLUB INC                                                           765\n",
              "UNITED STATES BOWLING CONGRESS INC                                      700\n",
              "WASHINGTON STATE UNIVERSITY                                             492\n",
              "AMATEUR ATHLETIC UNION OF THE UNITED STATES INC                         408\n",
              "PTA TEXAS CONGRESS                                                      368\n",
              "SOROPTIMIST INTERNATIONAL OF THE AMERICAS INC                           331\n",
              "ALPHA PHI SIGMA                                                         313\n",
              "TOASTMASTERS INTERNATIONAL                                              293\n",
              "MOST WORSHIPFUL STRINGER FREE AND ACCEPTED MASONS                       287\n",
              "LITTLE LEAGUE BASEBALL INC                                              277\n",
              "INTERNATIONAL ASSOCIATION OF LIONS CLUBS                                266\n",
              "MOMS CLUB                                                               210\n",
              "INTERNATIONAL ASSOCIATION OF SHEET METAL AIR RAIL & TRANSPORTATION      206\n",
              "AMERICAN ASSOCIATION OF UNIVERSITY WOMEN                                197\n",
              "FARMERS EDUCATIONAL AND COOPERATIVE UNION OF AMERICA                    166\n",
              "KNIGHTS OF COLUMBUS                                                     158\n",
              "HABITAT FOR HUMANITY INTERNATIONAL INC                                  154\n",
              "TENNESSEE ORDER OF THE EASTERN STAR                                     151\n",
              "VETERANS OF FOREIGN WARS OF THE UNITED STATES AUXILIARY                 144\n",
              "PTA UTAH CONGRESS                                                       140\n",
              "THE UNITED STATES PONY CLUBS INC                                        136\n",
              "CIVITAN INTERNATIONAL                                                   131\n",
              "SIGMA BETA DELTA INC                                                    127\n",
              "HONOR SOCIETY OF PHI KAPPA PHI                                          107\n",
              "MONTANA 4-H FOUNDATION INC                                              107\n",
              "WASHINGTON STATE GRANGE                                                 106\n",
              "UNIVERSITY OF WYOMING                                                   105\n",
              "DEMOLAY INTERNATIONAL                                                   104\n",
              "SERTOMA INC                                                             103\n",
              "AIR FORCE ASSOCIATION                                                    99\n",
              "WORKERS UNITED                                                           97\n",
              "GAMMA THETA UPSILON                                                      92\n",
              "INTERNATIONAL ASSOCIATION OF FIRE FIGHTERS                               91\n",
              "SOCIETY OF SAINT VINCENT DE PAUL COUNCIL OF LOS ANGELES                  87\n",
              "ROTARY INTERNATIONAL                                                     84\n",
              "CALIFORNIA GARDEN CLUBS INC                                              76\n",
              "SWEET ADELINES INTERNATIONAL                                             73\n",
              "DISABLED AMERICAN VETERANS                                               73\n",
              "KLEIN SUPPORT GROUPS INC                                                 69\n",
              "CLEARCREEK I S D SUPPORT GROUPS                                          60\n",
              "VFW AUXILIARY DEPARTMENT OF OKLAHOMA INC                                 58\n",
              "DEPARTMENT OF KANSAS LADIES AUXILIARY TO THE VFW OF THE US INC           57\n",
              "CISD EDUCATIONAL SUPPORT GROUPS INC                                      57\n",
              "SONS OF CONFEDERATE VETERANS INC                                         56\n",
              "SLOW FOOD USA INC                                                        55\n",
              "NATIONAL YOUNG MENS SERVICE LEAGUE                                       54\n",
              "AMATEUR ATHLETIC UNION OF THE UNITED STATES                              52\n",
              "LAMBDA THETA ALPHA                                                       52\n",
              "UNITED FEDERATION OF DOLL CLUBS INC                                      50\n",
              "UNIVERSITY OF FLORIDA                                                    50\n",
              "Name: NAME, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gwVlG5BuW6w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1e11d4b-73fe-4120-fc38-9e3ad0f69330"
      },
      "source": [
        "# Look at ASK_AMT value counts for binning\n",
        "df_application.ASK_AMT.value_counts()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000       25398\n",
              "63981          3\n",
              "6725           3\n",
              "15583          3\n",
              "10478          3\n",
              "           ...  \n",
              "358652         1\n",
              "7221           1\n",
              "5472143        1\n",
              "461143         1\n",
              "26170          1\n",
              "Name: ASK_AMT, Length: 8747, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ye7TzsPiuW-P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "82e518d9-2d85-4f8b-d6e7-c9ec8c7169d9"
      },
      "source": [
        "# Visualize the value counts of ASK_AMT\n",
        "askamt = df_application.ASK_AMT.value_counts()\n",
        "askamt.plot.density()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0bdaa2f590>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZoAAAD4CAYAAADVTSCGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAWZklEQVR4nO3df5Bd5X3f8fc3KyGwCZgfiuNIciQXjd0lkwSyJXacyXhMUoShUX/AVDR2iEtDGkPjOJ1mhNNhHKbMGLdj7DTQhBgyMnEjiOx6ti4ttYOdpE0sWH4kRhCFtcBBCglrwMKNg4S03/5xH6yzyx7tXe15dPeu3q+ZOzr3Oc8593l2dfdzz3Oee05kJpIk1fIdg26AJGl5M2gkSVUZNJKkqgwaSVJVBo0kqaoVg27A8XD22Wfn+vXrB90MSRoaDz744Nczc3UX+zohgmb9+vVMTEwMuhmSNDQi4mtd7cuhM0lSVQaNJKkqg0aSVJVBI0mqyqCRJFVl0EiSqjJoJElVGTTqzEN/+QK7/mr/oJshaYk5Ib6wqePjn976xwA89eFLBtwSSUuJRzSSpKoMGklSVQaNJKkqg0aSVJVBI0mqyqCRJFVl0EiSqjJoJElVGTSSpKoMGklSVQaNJKmqqkETEZsiYndETEbE1jnWr4qIu8r6nRGxvrHuulK+OyIuapR/ICJ2RcSjEfG7EXFyzT5IkhanWtBExAhwC3AxMApcERGjs6pdBbyQmecANwM3lW1HgS3AucAm4NaIGImINcAvAGOZ+X3ASKknSVqiah7RXABMZuaezDwIbAc2z6qzGdhWlncAF0ZElPLtmXkgM58EJsv+oHfF6VMiYgXwGuCvKvZBkrRINYNmDfB04/neUjZnncw8BOwHzmrbNjP3Af8J+EvgGWB/Zv7vuV48Iq6OiImImJiamuqgO5KkYzFUkwEi4gx6RzsbgO8BXhsR756rbmbelpljmTm2evXq49lMSVJDzaDZB6xrPF9byuasU4bCTgeeO8q2Pw48mZlTmfky8BngR6q0XpLUiZpB8wCwMSI2RMRJ9E7aj8+qMw5cWZYvA+7LzCzlW8qstA3ARuB+ekNmb42I15RzORcCj1fsgyRpkardyjkzD0XEtcC99GaH3ZGZuyLiBmAiM8eB24E7I2ISeJ4yg6zUuxt4DDgEXJOZh4GdEbEDeKiUPwzcVqsPkqTFi94BxPI2NjaWExMTg27Gsrd+6/8A4KkPXzLglkharIh4MDPHutjXUE0GkCQNH4NGklSVQSNJqsqgkSRVZdBIkqoyaCRJVRk0kqSqDBpJUlUGjSSpKoNGklSVQSNJqsqgkSRVZdBIkqoyaCRJVRk0kqSqDBpJUlUGjSSpKoNGnTgR7tQq6dgYNOqEOSOpjUGjTpgzktoYNOrEtIc0kloYNOqEOSOpjUGjTqSDZ5JaGDTqhEc0ktoYNOqEQSOpjUGjTjgZQFIbg0adMGYktTFo1AmvDCCpjUGjTkybM5JaGDTqhkEjqYVBo044GUBSG4NGnTBmJLUxaNQJJwNIamPQqBNOBpDUxqBRJ7zWmaQ2Bo26Yc5IamHQqBPmjKQ2VYMmIjZFxO6ImIyIrXOsXxURd5X1OyNifWPddaV8d0Rc1Ch/XUTsiIg/j4jHI+JtNfug/jgXQFKbakETESPALcDFwChwRUSMzqp2FfBCZp4D3AzcVLYdBbYA5wKbgFvL/gA+DvyvzHwL8APA47X6IElavJpHNBcAk5m5JzMPAtuBzbPqbAa2leUdwIUREaV8e2YeyMwngUnggog4Hfgx4HaAzDyYmd+o2Af1yckAktrUDJo1wNON53tL2Zx1MvMQsB846yjbbgCmgN+OiIcj4hMR8dq5Xjwiro6IiYiYmJqa6qI/OgqHziS1GbbJACuA84H/kpnnAX8LvOrcD0Bm3paZY5k5tnr16uPZRklSQ82g2QesazxfW8rmrBMRK4DTgeeOsu1eYG9m7izlO+gFjwbMAxpJbWoGzQPAxojYEBEn0Tu5Pz6rzjhwZVm+DLgve9cyGQe2lFlpG4CNwP2Z+dfA0xHx5rLNhcBjFfugPnkJGkltVtTacWYeiohrgXuBEeCOzNwVETcAE5k5Tu+k/p0RMQk8Ty+MKPXuphcih4BrMvNw2fW/AT5VwmsP8N5afZAkLV61oAHIzHuAe2aVXd9Yfgm4vGXbG4Eb5yh/BBjrtqVaLA9oJLUZtskAkqQhY9BIkqoyaNQJh84ktTFo1AmvDCCpjUEjSarKoFEnHDqT1MagUSfMGUltDBpJUlUGjTrhJWgktTFo1AljRlIbg0aSVJVBo044ciapjUGjjpg0kuZm0KgTHtFIamPQSJKqMmjUCQ9oJLXpK2gi4jMRcUlEGEyak0Nnktr0Gxy3Av8CeCIiPhwRb67YJknSMtJX0GTmFzLzp4DzgaeAL0TEH0fEeyNiZc0Gajh4mwBJbfoeCouIs4CfAf4V8DDwcXrB8/kqLdNQcehMUpsV/VSKiP8GvBm4E/hHmflMWXVXREzUapwkafj1FTTAb2XmPc2CiFiVmQcyc6xCuzRkPKKR1KbfobP/MEfZn3TZEA03z9FIanPUI5qI+G5gDXBKRJwHRFl1GvCaym2TJC0D8w2dXURvAsBa4KON8m8CH6zUJg0hh84ktTlq0GTmNmBbRPyzzPz0cWqTJGkZmW/o7N2Z+TvA+oj4pdnrM/Ojc2wmSdK3zTd09try76m1G6Lh5tCZpDbzDZ39Zvn3V49PczSsnHUmqU2/F9X8SEScFhErI+L3I2IqIt5du3GSpOHX7/do/mFmvghcSu9aZ+cA/65WozR8HDqT1KbfoHlliO0S4Pcyc3+l9mhImTOS2vR7CZrPRcSfA38H/HxErAZeqtcsSdJy0e9tArYCPwKMZebLwN8Cm2s2TMMlHTuT1KLfIxqAt9D7Pk1zm0923B4NKWNGUpt+bxNwJ/D3gEeAw6U4MWgkSfPo94hmDBjNBY6PRMQmejdIGwE+kZkfnrV+Fb2w+iHgOeCfZ+ZTZd11wFX0gu0XMvPexnYjwASwLzMvXUibVIcjZ5La9Dvr7FHguxey4xIGtwAXA6PAFRExOqvaVcALmXkOcDNwU9l2FNgCnAtsAm4t+3vF+4HHF9Ie1WbSSJpbv0FzNvBYRNwbEeOvPObZ5gJgMjP3ZOZBYDuvnkCwGdhWlncAF0ZElPLt5cZqTwKTZX9ExFp606w/0WfbJUkD1O/Q2YeOYd9rgKcbz/cCP9xWJzMPRcR+4KxS/uVZ264pyx8Dfhn4zmNokypx6ExSm36nN/8BvSsCrCzLDwAPVWzXnCLiUuDZzHywj7pXR8RERExMTU0dh9ad2MwZSW36vdbZz9Ib2vrNUrQG+Ow8m+0D1jWery1lc9Yp06ZPpzcpoG3btwM/GRFP0RuKe2dE/M5cL56Zt2XmWGaOrV69ep6marE8opHUpt9zNNfQ+yP/IkBmPgF81zzbPABsjIgNEXESvZP7s8/rjANXluXLgPvKzLZxYEtErIqIDcBG4P7MvC4z12bm+rK/+zLTi3tK0hLW7zmaA5l5sHee/ttHH0f9DFvOuVwL3EtvevMdmbkrIm4AJjJzHLgduDMiJoHn6YUHpd7dwGPAIeCazDw85wtpSfDKAJLa9Bs0fxARHwROiYifAN4H/Pf5NsrMe4B7ZpVd31h+Cbi8ZdsbgRuPsu8vAV/qo+06DowZSW36HTrbCkwBXwF+jl54/PtajZIkLR99HdFk5nREfBb4bGY6hUuv4siZpDZHPaKJng9FxNeB3cDucnfN64+2nU483spZUpv5hs4+QG+22T/IzDMz80x6X7p8e0R8oHrrJElDb76geQ9wRbkMDACZuQd4N/DTNRumIeMBjaQW8wXNysz8+uzCcp5mZZ0maRiZM5LazBc0B49xnSRJwPyzzn4gIl6cozyAkyu0R0OqOessM3nly72SdNSgycyRo62XXuGsM0lt+v3CptQ3v1MjqcmgUSdmDJ0NrhmSliCDRp0wXCS1MWjUOa/kLKnJoFEnmuFizEhqMmjUiWa4eEAjqcmgUeec6iypyaBRN2Z8YXNwzZC09Bg06kTzKMagkdRk0KhzDp1JajJo1Il06ExSC4NGnfDKAJLaGDTqxMzpzUaNpCMMGnVu2pyR1GDQqBPp2JmkFgaNOjFj6MykkdRg0KhznqKR1GTQqBOOnElqY9CoI0fiZdpDGkkNBo06Z85IajJo1ImZQ2cmjaQjDBp1IlufSDrRGTTqnDkjqcmgUSe8qKakNgaNOpHOOpPUwqBR54wZSU0GjToxc+jMqJF0hEGjTsy8TcDAmiFpCaoaNBGxKSJ2R8RkRGydY/2qiLirrN8ZEesb664r5bsj4qJSti4ivhgRj0XEroh4f832S5IWr1rQRMQIcAtwMTAKXBERo7OqXQW8kJnnADcDN5VtR4EtwLnAJuDWsr9DwL/NzFHgrcA1c+xTA9AcLnMygKSmmkc0FwCTmbknMw8C24HNs+psBraV5R3AhRERpXx7Zh7IzCeBSeCCzHwmMx8CyMxvAo8Dayr2QcfAnJHUVDNo1gBPN57v5dWh8O06mXkI2A+c1c+2ZZjtPGDnXC8eEVdHxERETExNTR1zJ7Rw5oykpqGcDBARpwKfBn4xM1+cq05m3paZY5k5tnr16uPbwBOQs84ktakZNPuAdY3na0vZnHUiYgVwOvDc0baNiJX0QuZTmfmZKi3XgjW/sGnMSGqqGTQPABsjYkNEnETv5P74rDrjwJVl+TLgvux9HB4HtpRZaRuAjcD95fzN7cDjmfnRim3XInhAI6lpRa0dZ+ahiLgWuBcYAe7IzF0RcQMwkZnj9ELjzoiYBJ6nF0aUencDj9GbaXZNZh6OiB8F3gN8JSIeKS/1wcy8p1Y/1B+HziS1qRY0ACUA7plVdn1j+SXg8pZtbwRunFX2f4DovqVaLG/lLKnNUE4G0NLjlQEktTFo1DnvsCmpyaBRJ5rnZTyikdRk0KgTDp1JamPQqHNe60xSk0GjbpgtkloYNOrEjCsDGDqSGgwadc5ZZ5KaDBp1YuaVAQbXDklLj0GjTjSzxckAkpoMGnXOmJHUZNCoEw6dSWpj0KgTMycAmDSSjjBo1Ilpj2gktTBo1Inpae+wKWluBo06cbgRNM3QkSSDRp1oTmk2ZiQ1GTTqRPOIxnM0kpoMGnXi8IwjGpNG0hEGjTox47yMOSOpwaBRJw5PH1l2LoCkJoNGnTg8fSRpHDqT1GTQqBMzztGYM5IaDBp1ojl0Zs5IajJo1IkZ36PxkEZSg0GjThz2EjSSWhg06sTML2waNZKOMGjUiWknA0hqYdCoE16CRlIbg0ad8KKaktoYNOqE52gktTFo1AkvQSOpjUGjTvg9GkltDBp1ojl0duDQ9FFqSjrRGDTqxOFMTl21AoBvHTw84NZIWkoMGnVieroZNIcG3BpJS4lBo04cnk5eu2oE8IhG0kxVgyYiNkXE7oiYjIitc6xfFRF3lfU7I2J9Y911pXx3RFzU7z41GNOZrFoxwsqRMGgkzVAtaCJiBLgFuBgYBa6IiNFZ1a4CXsjMc4CbgZvKtqPAFuBcYBNwa0SM9LlPDcC3Dh7mpBXfwSkrR/g7h84kNayouO8LgMnM3AMQEduBzcBjjTqbgQ+V5R3Ar0dElPLtmXkAeDIiJsv+6GOfnbn0P/8RL718bDOoFjPFd1GTgxex8WJe9+nnv8XlY+uY+uYBtv3J1/i/X31uEXvrT1R/BWm4nfGak7j7X79t0M2oGjRrgKcbz/cCP9xWJzMPRcR+4KxS/uVZ264py/PtE4CIuBq4GuCNb3zjMXXgnNWn8vLhRfz5XcRfwsX8Ee1l9fF93R9c9zre89bv5Z1v+S4++8i+6teh8XbR0vxOO3nloJsA1A2agcrM24DbAMbGxo7pr9LHtpzXaZtOBKPfcxo/Mfr6QTdD0hJSczLAPmBd4/naUjZnnYhYAZwOPHeUbfvZpyRpCakZNA8AGyNiQ0ScRO/k/visOuPAlWX5MuC+7J3cGAe2lFlpG4CNwP197lOStIRUGzor51yuBe4FRoA7MnNXRNwATGTmOHA7cGc52f88veCg1Lub3kn+Q8A1mXkYYK591uqDJGnx4kS4AOLY2FhOTEwMuhmSNDQi4sHMHOtiX14ZQJJUlUEjSarKoJEkVWXQSJKqOiEmA0TEFPC1Ab382cDXB/Tag2B/lzf7u7w1+/u9mbm6i52eEEEzSBEx0dXMjWFgf5c3+7u81eqvQ2eSpKoMGklSVQZNfbcNugHHmf1d3uzv8lalv56jkSRV5RGNJKkqg0aSVJVBs0ARcXlE7IqI6YgYm7XuuoiYjIjdEXFRo3xTKZuMiK2N8g0RsbOU31VufUC5PcJdpXxnRKw/Xv07Vm19HAYRcUdEPBsRjzbKzoyIz0fEE+XfM0p5RMSvlX7+WUSc39jmylL/iYi4slH+QxHxlbLNr8ViboHagYhYFxFfjIjHyv/l95fyZdnniDg5Iu6PiD8t/f3VUr7g999C3+ODEhEjEfFwRHyuPB9sXzPTxwIewN8H3gx8CRhrlI8CfwqsAjYAX6V3K4ORsvwm4KRSZ7RsczewpSz/BvDzZfl9wG+U5S3AXYPu9zw/k9Y+DsMD+DHgfODRRtlHgK1leStwU1l+F/A/6d31+q3AzlJ+JrCn/HtGWT6jrLu/1I2y7cUD7u8bgPPL8ncCf1H+/y7LPpc2nFqWVwI7S9sW9P47lvf4APv8S8B/BT5Xng+0rx7RLFBmPp6Zu+dYtRnYnpkHMvNJYBK4oDwmM3NPZh4EtgObyye8dwI7yvbbgH/c2Ne2srwDuHDQn4LnMWcfB9ymvmXmH9K7H1JT83cw+3fzyez5MvC6iHgDcBHw+cx8PjNfAD4PbCrrTsvML2fvHfzJxr4GIjOfycyHyvI3gceBNSzTPpd2/7/ydGV5JAt//y3oPV65W60iYi1wCfCJ8vxY/tZ02leDpjtrgKcbz/eWsrbys4BvZOahWeUz9lXW7y/1l6q2Pg6z12fmM2X5r4HXl+WF/p7XlOXZ5UtCGSo5j96n/GXb5zKU9AjwLL1A/CoLf/8t9OcwKB8DfhmYLs+P5W9Np301aOYQEV+IiEfneAzNp3R1p3wqX3bfA4iIU4FPA7+YmS821y23Pmfm4cz8QWAtvU/lbxlwk6qIiEuBZzPzwUG3panarZyHWWb++DFstg9Y13i+tpTRUv4cvSGIFeWTRLP+K/vaGxErgNNL/aXqaH0fVn8TEW/IzGfKUNCzpbytr/uAd8wq/1IpXztH/YGKiJX0QuZTmfmZUrys+wyQmd+IiC8Cb2Ph77+FvscH4e3AT0bEu4CTgdOAjzPovg7yhNUwP3j1ZIBzmXnybA+9E2cryvIGjpw8O7ds83vMPEH3vrJ8DTNP0N096P7O87No7eOwPID1zJwM8B+ZeWL8I2X5EmaeGL+/lJ8JPEnvpPgZZfnMsm72ifF3DbivQe+8ycdmlS/LPgOrgdeV5VOAPwIuXej771je4wP+Pb+DI5MBBtrXgf4ghvEB/BN645IHgL8B7m2s+xV6Y7+7acyyoTdr5y/Kul9plL+pvCEny3+EVaX85PJ8sqx/06D73cfPZc4+DsMD+F3gGeDl8ru9it449e8DTwBfaPwBDeCW0s+vMPPDxr8sv7NJ4L2N8jHg0bLNr1OuyDHA/v4ovWGxPwMeKY93Ldc+A98PPFz6+yhwfSlf8Ptvoe/xAf+e38GRoBloX70EjSSpKicDSJKqMmgkSVUZNJKkqgwaSVJVBo0kqSqDRpJUlUEjSarq/wPIKzEUeQEitwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_oXqPk2uXBU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1830d420-44f1-4207-df28-24a312443e32"
      },
      "source": [
        "# Determine which values to replace if counts are less than ...?\n",
        "replace_askamt = list(askamt[askamt < 3].index)\n",
        "\n",
        "# Replace in dataframe\n",
        "for app in replace_askamt:\n",
        "    df_application.ASK_AMT = df_application.ASK_AMT.replace(app,\"Other\")\n",
        "    \n",
        "# Check to make sure binning was successful\n",
        "df_application.ASK_AMT.value_counts()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000     25398\n",
              "Other     8889\n",
              "63981        3\n",
              "15583        3\n",
              "6725         3\n",
              "10478        3\n",
              "Name: ASK_AMT, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHZUvloIuXEq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b786013-dc38-4600-86c3-5a783c03af8c"
      },
      "source": [
        "df_application.dtypes"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NAME                      object\n",
              "APPLICATION_TYPE          object\n",
              "AFFILIATION               object\n",
              "CLASSIFICATION            object\n",
              "USE_CASE                  object\n",
              "ORGANIZATION              object\n",
              "STATUS                     int64\n",
              "INCOME_AMT                object\n",
              "SPECIAL_CONSIDERATIONS    object\n",
              "ASK_AMT                   object\n",
              "IS_SUCCESSFUL              int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09u4O22AuXHw"
      },
      "source": [
        "# Generate our categorical variable lists\n",
        "application_cat = df_application.dtypes[df_application.dtypes == \"object\"].index.tolist()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbVW72SSuXK0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "outputId": "98c49093-8295-43f1-dec8-d39989a62ce7"
      },
      "source": [
        "# Create a OneHotEncoder instance\n",
        "enc = OneHotEncoder(sparse=False)\n",
        "\n",
        "# Fit and transform the OneHotEncoder using the categorical variable list\n",
        "encode_df = pd.DataFrame(enc.fit_transform(df_application[application_cat]))\n",
        "\n",
        "# Add the encoded variable names to the dataframe\n",
        "encode_df.columns = enc.get_feature_names(application_cat)\n",
        "encode_df.head()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NAME_AIR FORCE ASSOCIATION</th>\n",
              "      <th>NAME_ALPHA PHI SIGMA</th>\n",
              "      <th>NAME_AMATEUR ATHLETIC UNION OF THE UNITED STATES</th>\n",
              "      <th>NAME_AMATEUR ATHLETIC UNION OF THE UNITED STATES INC</th>\n",
              "      <th>NAME_AMERICAN ASSOCIATION OF UNIVERSITY WOMEN</th>\n",
              "      <th>NAME_CALIFORNIA GARDEN CLUBS INC</th>\n",
              "      <th>NAME_CISD EDUCATIONAL SUPPORT GROUPS INC</th>\n",
              "      <th>NAME_CIVITAN INTERNATIONAL</th>\n",
              "      <th>NAME_CLEARCREEK I S D SUPPORT GROUPS</th>\n",
              "      <th>NAME_DEMOLAY INTERNATIONAL</th>\n",
              "      <th>NAME_DEPARTMENT OF KANSAS LADIES AUXILIARY TO THE VFW OF THE US INC</th>\n",
              "      <th>NAME_DISABLED AMERICAN VETERANS</th>\n",
              "      <th>NAME_FARMERS EDUCATIONAL AND COOPERATIVE UNION OF AMERICA</th>\n",
              "      <th>NAME_GAMMA THETA UPSILON</th>\n",
              "      <th>NAME_HABITAT FOR HUMANITY INTERNATIONAL INC</th>\n",
              "      <th>NAME_HONOR SOCIETY OF PHI KAPPA PHI</th>\n",
              "      <th>NAME_INTERNATIONAL ASSOCIATION OF FIRE FIGHTERS</th>\n",
              "      <th>NAME_INTERNATIONAL ASSOCIATION OF LIONS CLUBS</th>\n",
              "      <th>NAME_INTERNATIONAL ASSOCIATION OF SHEET METAL AIR RAIL &amp; TRANSPORTATION</th>\n",
              "      <th>NAME_KLEIN SUPPORT GROUPS INC</th>\n",
              "      <th>NAME_KNIGHTS OF COLUMBUS</th>\n",
              "      <th>NAME_LAMBDA THETA ALPHA</th>\n",
              "      <th>NAME_LITTLE LEAGUE BASEBALL INC</th>\n",
              "      <th>NAME_MOMS CLUB</th>\n",
              "      <th>NAME_MONTANA 4-H FOUNDATION INC</th>\n",
              "      <th>NAME_MOST WORSHIPFUL STRINGER FREE AND ACCEPTED MASONS</th>\n",
              "      <th>NAME_NATIONAL YOUNG MENS SERVICE LEAGUE</th>\n",
              "      <th>NAME_Other</th>\n",
              "      <th>NAME_PARENT BOOSTER USA INC</th>\n",
              "      <th>NAME_PTA TEXAS CONGRESS</th>\n",
              "      <th>NAME_PTA UTAH CONGRESS</th>\n",
              "      <th>NAME_ROTARY INTERNATIONAL</th>\n",
              "      <th>NAME_SERTOMA INC</th>\n",
              "      <th>NAME_SIGMA BETA DELTA INC</th>\n",
              "      <th>NAME_SLOW FOOD USA INC</th>\n",
              "      <th>NAME_SOCIETY OF SAINT VINCENT DE PAUL COUNCIL OF LOS ANGELES</th>\n",
              "      <th>NAME_SONS OF CONFEDERATE VETERANS INC</th>\n",
              "      <th>NAME_SOROPTIMIST INTERNATIONAL OF THE AMERICAS INC</th>\n",
              "      <th>NAME_SWEET ADELINES INTERNATIONAL</th>\n",
              "      <th>NAME_TENNESSEE ORDER OF THE EASTERN STAR</th>\n",
              "      <th>...</th>\n",
              "      <th>APPLICATION_TYPE_T7</th>\n",
              "      <th>APPLICATION_TYPE_T8</th>\n",
              "      <th>AFFILIATION_CompanySponsored</th>\n",
              "      <th>AFFILIATION_Family/Parent</th>\n",
              "      <th>AFFILIATION_Independent</th>\n",
              "      <th>AFFILIATION_National</th>\n",
              "      <th>AFFILIATION_Other</th>\n",
              "      <th>AFFILIATION_Regional</th>\n",
              "      <th>CLASSIFICATION_C1000</th>\n",
              "      <th>CLASSIFICATION_C1200</th>\n",
              "      <th>CLASSIFICATION_C2000</th>\n",
              "      <th>CLASSIFICATION_C2100</th>\n",
              "      <th>CLASSIFICATION_C3000</th>\n",
              "      <th>CLASSIFICATION_Other</th>\n",
              "      <th>USE_CASE_CommunityServ</th>\n",
              "      <th>USE_CASE_Heathcare</th>\n",
              "      <th>USE_CASE_Other</th>\n",
              "      <th>USE_CASE_Preservation</th>\n",
              "      <th>USE_CASE_ProductDev</th>\n",
              "      <th>ORGANIZATION_Association</th>\n",
              "      <th>ORGANIZATION_Co-operative</th>\n",
              "      <th>ORGANIZATION_Corporation</th>\n",
              "      <th>ORGANIZATION_Trust</th>\n",
              "      <th>INCOME_AMT_0</th>\n",
              "      <th>INCOME_AMT_1-9999</th>\n",
              "      <th>INCOME_AMT_10000-24999</th>\n",
              "      <th>INCOME_AMT_100000-499999</th>\n",
              "      <th>INCOME_AMT_10M-50M</th>\n",
              "      <th>INCOME_AMT_1M-5M</th>\n",
              "      <th>INCOME_AMT_25000-99999</th>\n",
              "      <th>INCOME_AMT_50M+</th>\n",
              "      <th>INCOME_AMT_5M-10M</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
              "      <th>ASK_AMT_10478</th>\n",
              "      <th>ASK_AMT_15583</th>\n",
              "      <th>ASK_AMT_5000</th>\n",
              "      <th>ASK_AMT_63981</th>\n",
              "      <th>ASK_AMT_6725</th>\n",
              "      <th>ASK_AMT_Other</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  99 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   NAME_AIR FORCE ASSOCIATION  ...  ASK_AMT_Other\n",
              "0                         0.0  ...            0.0\n",
              "1                         0.0  ...            1.0\n",
              "2                         0.0  ...            0.0\n",
              "3                         0.0  ...            1.0\n",
              "4                         0.0  ...            1.0\n",
              "\n",
              "[5 rows x 99 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wi1u8hqCuXOS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "outputId": "a26f0fb0-b12b-4d3b-e51f-704ff50d9dba"
      },
      "source": [
        "# Merge one-hot encoded features and drop the originals\n",
        "df_application = df_application.merge(encode_df,left_index=True, right_index=True)\n",
        "df_application = df_application.drop(application_cat,1)\n",
        "df_application.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>STATUS</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "      <th>NAME_AIR FORCE ASSOCIATION</th>\n",
              "      <th>NAME_ALPHA PHI SIGMA</th>\n",
              "      <th>NAME_AMATEUR ATHLETIC UNION OF THE UNITED STATES</th>\n",
              "      <th>NAME_AMATEUR ATHLETIC UNION OF THE UNITED STATES INC</th>\n",
              "      <th>NAME_AMERICAN ASSOCIATION OF UNIVERSITY WOMEN</th>\n",
              "      <th>NAME_CALIFORNIA GARDEN CLUBS INC</th>\n",
              "      <th>NAME_CISD EDUCATIONAL SUPPORT GROUPS INC</th>\n",
              "      <th>NAME_CIVITAN INTERNATIONAL</th>\n",
              "      <th>NAME_CLEARCREEK I S D SUPPORT GROUPS</th>\n",
              "      <th>NAME_DEMOLAY INTERNATIONAL</th>\n",
              "      <th>NAME_DEPARTMENT OF KANSAS LADIES AUXILIARY TO THE VFW OF THE US INC</th>\n",
              "      <th>NAME_DISABLED AMERICAN VETERANS</th>\n",
              "      <th>NAME_FARMERS EDUCATIONAL AND COOPERATIVE UNION OF AMERICA</th>\n",
              "      <th>NAME_GAMMA THETA UPSILON</th>\n",
              "      <th>NAME_HABITAT FOR HUMANITY INTERNATIONAL INC</th>\n",
              "      <th>NAME_HONOR SOCIETY OF PHI KAPPA PHI</th>\n",
              "      <th>NAME_INTERNATIONAL ASSOCIATION OF FIRE FIGHTERS</th>\n",
              "      <th>NAME_INTERNATIONAL ASSOCIATION OF LIONS CLUBS</th>\n",
              "      <th>NAME_INTERNATIONAL ASSOCIATION OF SHEET METAL AIR RAIL &amp; TRANSPORTATION</th>\n",
              "      <th>NAME_KLEIN SUPPORT GROUPS INC</th>\n",
              "      <th>NAME_KNIGHTS OF COLUMBUS</th>\n",
              "      <th>NAME_LAMBDA THETA ALPHA</th>\n",
              "      <th>NAME_LITTLE LEAGUE BASEBALL INC</th>\n",
              "      <th>NAME_MOMS CLUB</th>\n",
              "      <th>NAME_MONTANA 4-H FOUNDATION INC</th>\n",
              "      <th>NAME_MOST WORSHIPFUL STRINGER FREE AND ACCEPTED MASONS</th>\n",
              "      <th>NAME_NATIONAL YOUNG MENS SERVICE LEAGUE</th>\n",
              "      <th>NAME_Other</th>\n",
              "      <th>NAME_PARENT BOOSTER USA INC</th>\n",
              "      <th>NAME_PTA TEXAS CONGRESS</th>\n",
              "      <th>NAME_PTA UTAH CONGRESS</th>\n",
              "      <th>NAME_ROTARY INTERNATIONAL</th>\n",
              "      <th>NAME_SERTOMA INC</th>\n",
              "      <th>NAME_SIGMA BETA DELTA INC</th>\n",
              "      <th>NAME_SLOW FOOD USA INC</th>\n",
              "      <th>NAME_SOCIETY OF SAINT VINCENT DE PAUL COUNCIL OF LOS ANGELES</th>\n",
              "      <th>NAME_SONS OF CONFEDERATE VETERANS INC</th>\n",
              "      <th>NAME_SOROPTIMIST INTERNATIONAL OF THE AMERICAS INC</th>\n",
              "      <th>...</th>\n",
              "      <th>APPLICATION_TYPE_T7</th>\n",
              "      <th>APPLICATION_TYPE_T8</th>\n",
              "      <th>AFFILIATION_CompanySponsored</th>\n",
              "      <th>AFFILIATION_Family/Parent</th>\n",
              "      <th>AFFILIATION_Independent</th>\n",
              "      <th>AFFILIATION_National</th>\n",
              "      <th>AFFILIATION_Other</th>\n",
              "      <th>AFFILIATION_Regional</th>\n",
              "      <th>CLASSIFICATION_C1000</th>\n",
              "      <th>CLASSIFICATION_C1200</th>\n",
              "      <th>CLASSIFICATION_C2000</th>\n",
              "      <th>CLASSIFICATION_C2100</th>\n",
              "      <th>CLASSIFICATION_C3000</th>\n",
              "      <th>CLASSIFICATION_Other</th>\n",
              "      <th>USE_CASE_CommunityServ</th>\n",
              "      <th>USE_CASE_Heathcare</th>\n",
              "      <th>USE_CASE_Other</th>\n",
              "      <th>USE_CASE_Preservation</th>\n",
              "      <th>USE_CASE_ProductDev</th>\n",
              "      <th>ORGANIZATION_Association</th>\n",
              "      <th>ORGANIZATION_Co-operative</th>\n",
              "      <th>ORGANIZATION_Corporation</th>\n",
              "      <th>ORGANIZATION_Trust</th>\n",
              "      <th>INCOME_AMT_0</th>\n",
              "      <th>INCOME_AMT_1-9999</th>\n",
              "      <th>INCOME_AMT_10000-24999</th>\n",
              "      <th>INCOME_AMT_100000-499999</th>\n",
              "      <th>INCOME_AMT_10M-50M</th>\n",
              "      <th>INCOME_AMT_1M-5M</th>\n",
              "      <th>INCOME_AMT_25000-99999</th>\n",
              "      <th>INCOME_AMT_50M+</th>\n",
              "      <th>INCOME_AMT_5M-10M</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
              "      <th>ASK_AMT_10478</th>\n",
              "      <th>ASK_AMT_15583</th>\n",
              "      <th>ASK_AMT_5000</th>\n",
              "      <th>ASK_AMT_63981</th>\n",
              "      <th>ASK_AMT_6725</th>\n",
              "      <th>ASK_AMT_Other</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  101 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   STATUS  IS_SUCCESSFUL  ...  ASK_AMT_6725  ASK_AMT_Other\n",
              "0       1              1  ...           0.0            0.0\n",
              "1       1              1  ...           0.0            1.0\n",
              "2       1              0  ...           0.0            0.0\n",
              "3       1              1  ...           0.0            1.0\n",
              "4       1              1  ...           0.0            1.0\n",
              "\n",
              "[5 rows x 101 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_7LkVbYwixs"
      },
      "source": [
        "# Split our preprocessed data into our features and target arrays\n",
        "y = df_application[\"IS_SUCCESSFUL\"].values\n",
        "X = df_application.drop([\"IS_SUCCESSFUL\"],1).values\n",
        "\n",
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQa3vrVuwi5h"
      },
      "source": [
        "# Create a StandardScaler instances\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoXH-m18wi_M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ece41b58-5ad9-4f9f-ad05-bd8a57106e94"
      },
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "number_input_features = len(X_train[0])\n",
        "hidden_nodes_layer1 = 200\n",
        "hidden_nodes_layer2 = 90\n",
        "#hidden_nodes_layer3 = 40\n",
        "\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(\n",
        "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
        ")\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
        "\n",
        "# Third hidden layer\n",
        "#nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 200)               20200     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 90)                18090     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 91        \n",
            "=================================================================\n",
            "Total params: 38,381\n",
            "Trainable params: 38,381\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3uOi45hwjEE"
      },
      "source": [
        "# Define the checkpoint path and filenames\n",
        "os.makedirs(\"checkpoints/\",exist_ok=True)\n",
        "checkpoint_path = \"checkpoints/weights.{epoch:02d}.hdf5\""
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSrA0mlWwjKq"
      },
      "source": [
        "# Compile the model\n",
        "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUGANjD8yk6L"
      },
      "source": [
        "# Create a callback that saves the model's weights every 5 epochs\n",
        "cp_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    verbose=1,\n",
        "    save_weights_only=True,\n",
        "    save_freq=1000)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9vWu0OgyUUh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52e55c66-20b7-4ea8-9d6d-4ea57a48953e"
      },
      "source": [
        "# Train the model\n",
        "fit_model = nn.fit(X_train_scaled,y_train,epochs=500, callbacks=[cp_callback])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4967 - accuracy: 0.7557\n",
            "Epoch 2/500\n",
            "183/804 [=====>........................] - ETA: 1s - loss: 0.4869 - accuracy: 0.7582\n",
            "Epoch 00002: saving model to checkpoints/weights.02.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4803 - accuracy: 0.7642\n",
            "Epoch 3/500\n",
            "385/804 [=============>................] - ETA: 0s - loss: 0.4726 - accuracy: 0.7685\n",
            "Epoch 00003: saving model to checkpoints/weights.03.hdf5\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4766 - accuracy: 0.7660\n",
            "Epoch 4/500\n",
            "582/804 [====================>.........] - ETA: 0s - loss: 0.4733 - accuracy: 0.7687\n",
            "Epoch 00004: saving model to checkpoints/weights.04.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4749 - accuracy: 0.7676\n",
            "Epoch 5/500\n",
            "783/804 [============================>.] - ETA: 0s - loss: 0.4707 - accuracy: 0.7693\n",
            "Epoch 00005: saving model to checkpoints/weights.05.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4720 - accuracy: 0.7688\n",
            "Epoch 6/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4717 - accuracy: 0.7690\n",
            "Epoch 7/500\n",
            "175/804 [=====>........................] - ETA: 1s - loss: 0.4744 - accuracy: 0.7679\n",
            "Epoch 00007: saving model to checkpoints/weights.07.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4709 - accuracy: 0.7704\n",
            "Epoch 8/500\n",
            "365/804 [============>.................] - ETA: 0s - loss: 0.4717 - accuracy: 0.7703\n",
            "Epoch 00008: saving model to checkpoints/weights.08.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4702 - accuracy: 0.7701\n",
            "Epoch 9/500\n",
            "561/804 [===================>..........] - ETA: 0s - loss: 0.4685 - accuracy: 0.7698\n",
            "Epoch 00009: saving model to checkpoints/weights.09.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4693 - accuracy: 0.7698\n",
            "Epoch 10/500\n",
            "739/804 [==========================>...] - ETA: 0s - loss: 0.4683 - accuracy: 0.7722\n",
            "Epoch 00010: saving model to checkpoints/weights.10.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4679 - accuracy: 0.7720\n",
            "Epoch 11/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4680 - accuracy: 0.7710\n",
            "Epoch 12/500\n",
            "137/804 [====>.........................] - ETA: 1s - loss: 0.4613 - accuracy: 0.7767\n",
            "Epoch 00012: saving model to checkpoints/weights.12.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4673 - accuracy: 0.7726\n",
            "Epoch 13/500\n",
            "350/804 [============>.................] - ETA: 0s - loss: 0.4690 - accuracy: 0.7686\n",
            "Epoch 00013: saving model to checkpoints/weights.13.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4668 - accuracy: 0.7724\n",
            "Epoch 14/500\n",
            "539/804 [===================>..........] - ETA: 0s - loss: 0.4656 - accuracy: 0.7705\n",
            "Epoch 00014: saving model to checkpoints/weights.14.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4667 - accuracy: 0.7711\n",
            "Epoch 15/500\n",
            "737/804 [==========================>...] - ETA: 0s - loss: 0.4653 - accuracy: 0.7724\n",
            "Epoch 00015: saving model to checkpoints/weights.15.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4659 - accuracy: 0.7718\n",
            "Epoch 16/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4657 - accuracy: 0.7736\n",
            "Epoch 17/500\n",
            "132/804 [===>..........................] - ETA: 1s - loss: 0.4613 - accuracy: 0.7734\n",
            "Epoch 00017: saving model to checkpoints/weights.17.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4650 - accuracy: 0.7729\n",
            "Epoch 18/500\n",
            "313/804 [==========>...................] - ETA: 0s - loss: 0.4610 - accuracy: 0.7767\n",
            "Epoch 00018: saving model to checkpoints/weights.18.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4644 - accuracy: 0.7724\n",
            "Epoch 19/500\n",
            "520/804 [==================>...........] - ETA: 0s - loss: 0.4664 - accuracy: 0.7715\n",
            "Epoch 00019: saving model to checkpoints/weights.19.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4641 - accuracy: 0.7739\n",
            "Epoch 20/500\n",
            "712/804 [=========================>....] - ETA: 0s - loss: 0.4615 - accuracy: 0.7761\n",
            "Epoch 00020: saving model to checkpoints/weights.20.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4637 - accuracy: 0.7745\n",
            "Epoch 21/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4632 - accuracy: 0.7745\n",
            "Epoch 22/500\n",
            "111/804 [===>..........................] - ETA: 1s - loss: 0.4686 - accuracy: 0.7689\n",
            "Epoch 00022: saving model to checkpoints/weights.22.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4630 - accuracy: 0.7741\n",
            "Epoch 23/500\n",
            "293/804 [=========>....................] - ETA: 0s - loss: 0.4630 - accuracy: 0.7740\n",
            "Epoch 00023: saving model to checkpoints/weights.23.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4625 - accuracy: 0.7745\n",
            "Epoch 24/500\n",
            "498/804 [=================>............] - ETA: 0s - loss: 0.4651 - accuracy: 0.7720\n",
            "Epoch 00024: saving model to checkpoints/weights.24.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4625 - accuracy: 0.7746\n",
            "Epoch 25/500\n",
            "691/804 [========================>.....] - ETA: 0s - loss: 0.4605 - accuracy: 0.7753\n",
            "Epoch 00025: saving model to checkpoints/weights.25.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4613 - accuracy: 0.7746\n",
            "Epoch 26/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4619 - accuracy: 0.7755\n",
            "Epoch 27/500\n",
            " 81/804 [==>...........................] - ETA: 1s - loss: 0.4560 - accuracy: 0.7755\n",
            "Epoch 00027: saving model to checkpoints/weights.27.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4610 - accuracy: 0.7741\n",
            "Epoch 28/500\n",
            "267/804 [========>.....................] - ETA: 1s - loss: 0.4643 - accuracy: 0.7724\n",
            "Epoch 00028: saving model to checkpoints/weights.28.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4614 - accuracy: 0.7747\n",
            "Epoch 29/500\n",
            "462/804 [================>.............] - ETA: 0s - loss: 0.4634 - accuracy: 0.7714\n",
            "Epoch 00029: saving model to checkpoints/weights.29.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4610 - accuracy: 0.7748\n",
            "Epoch 30/500\n",
            "670/804 [========================>.....] - ETA: 0s - loss: 0.4585 - accuracy: 0.7769\n",
            "Epoch 00030: saving model to checkpoints/weights.30.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4602 - accuracy: 0.7760\n",
            "Epoch 31/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4605 - accuracy: 0.7756\n",
            "Epoch 32/500\n",
            " 55/804 [=>............................] - ETA: 1s - loss: 0.4640 - accuracy: 0.7744\n",
            "Epoch 00032: saving model to checkpoints/weights.32.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4602 - accuracy: 0.7755\n",
            "Epoch 33/500\n",
            "264/804 [========>.....................] - ETA: 1s - loss: 0.4598 - accuracy: 0.7760\n",
            "Epoch 00033: saving model to checkpoints/weights.33.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4600 - accuracy: 0.7756\n",
            "Epoch 34/500\n",
            "452/804 [===============>..............] - ETA: 0s - loss: 0.4540 - accuracy: 0.7814\n",
            "Epoch 00034: saving model to checkpoints/weights.34.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4595 - accuracy: 0.7758\n",
            "Epoch 35/500\n",
            "657/804 [=======================>......] - ETA: 0s - loss: 0.4613 - accuracy: 0.7744\n",
            "Epoch 00035: saving model to checkpoints/weights.35.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4592 - accuracy: 0.7759\n",
            "Epoch 36/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4587 - accuracy: 0.7755\n",
            "Epoch 37/500\n",
            " 55/804 [=>............................] - ETA: 1s - loss: 0.4535 - accuracy: 0.7881\n",
            "Epoch 00037: saving model to checkpoints/weights.37.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4592 - accuracy: 0.7762\n",
            "Epoch 38/500\n",
            "252/804 [========>.....................] - ETA: 1s - loss: 0.4598 - accuracy: 0.7773\n",
            "Epoch 00038: saving model to checkpoints/weights.38.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4589 - accuracy: 0.7760\n",
            "Epoch 39/500\n",
            "447/804 [===============>..............] - ETA: 0s - loss: 0.4582 - accuracy: 0.7733\n",
            "Epoch 00039: saving model to checkpoints/weights.39.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4586 - accuracy: 0.7749\n",
            "Epoch 40/500\n",
            "638/804 [======================>.......] - ETA: 0s - loss: 0.4569 - accuracy: 0.7766\n",
            "Epoch 00040: saving model to checkpoints/weights.40.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4582 - accuracy: 0.7766\n",
            "Epoch 41/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4578 - accuracy: 0.7769\n",
            "Epoch 42/500\n",
            " 24/804 [..............................] - ETA: 1s - loss: 0.4220 - accuracy: 0.7956\n",
            "Epoch 00042: saving model to checkpoints/weights.42.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4582 - accuracy: 0.7765\n",
            "Epoch 43/500\n",
            "222/804 [=======>......................] - ETA: 1s - loss: 0.4549 - accuracy: 0.7759\n",
            "Epoch 00043: saving model to checkpoints/weights.43.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4579 - accuracy: 0.7774\n",
            "Epoch 44/500\n",
            "424/804 [==============>...............] - ETA: 0s - loss: 0.4594 - accuracy: 0.7759\n",
            "Epoch 00044: saving model to checkpoints/weights.44.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4577 - accuracy: 0.7765\n",
            "Epoch 45/500\n",
            "605/804 [=====================>........] - ETA: 0s - loss: 0.4580 - accuracy: 0.7763\n",
            "Epoch 00045: saving model to checkpoints/weights.45.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4575 - accuracy: 0.7769\n",
            "Epoch 46/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4574 - accuracy: 0.7759\n",
            "Epoch 47/500\n",
            "  1/804 [..............................] - ETA: 1s - loss: 0.3543 - accuracy: 0.9062\n",
            "Epoch 00047: saving model to checkpoints/weights.47.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4571 - accuracy: 0.7767\n",
            "Epoch 48/500\n",
            "190/804 [======>.......................] - ETA: 1s - loss: 0.4591 - accuracy: 0.7699\n",
            "Epoch 00048: saving model to checkpoints/weights.48.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4568 - accuracy: 0.7754\n",
            "Epoch 49/500\n",
            "396/804 [=============>................] - ETA: 0s - loss: 0.4555 - accuracy: 0.7777\n",
            "Epoch 00049: saving model to checkpoints/weights.49.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4570 - accuracy: 0.7766\n",
            "Epoch 50/500\n",
            "602/804 [=====================>........] - ETA: 0s - loss: 0.4580 - accuracy: 0.7739\n",
            "Epoch 00050: saving model to checkpoints/weights.50.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4572 - accuracy: 0.7764\n",
            "Epoch 51/500\n",
            "790/804 [============================>.] - ETA: 0s - loss: 0.4562 - accuracy: 0.7781\n",
            "Epoch 00051: saving model to checkpoints/weights.51.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4566 - accuracy: 0.7773\n",
            "Epoch 52/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4566 - accuracy: 0.7766\n",
            "Epoch 53/500\n",
            "165/804 [=====>........................] - ETA: 1s - loss: 0.4460 - accuracy: 0.7848\n",
            "Epoch 00053: saving model to checkpoints/weights.53.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4565 - accuracy: 0.7759\n",
            "Epoch 54/500\n",
            "374/804 [============>.................] - ETA: 0s - loss: 0.4543 - accuracy: 0.7778\n",
            "Epoch 00054: saving model to checkpoints/weights.54.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4566 - accuracy: 0.7768\n",
            "Epoch 55/500\n",
            "569/804 [====================>.........] - ETA: 0s - loss: 0.4519 - accuracy: 0.7802\n",
            "Epoch 00055: saving model to checkpoints/weights.55.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4563 - accuracy: 0.7771\n",
            "Epoch 56/500\n",
            "767/804 [===========================>..] - ETA: 0s - loss: 0.4560 - accuracy: 0.7773\n",
            "Epoch 00056: saving model to checkpoints/weights.56.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4565 - accuracy: 0.7769\n",
            "Epoch 57/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4562 - accuracy: 0.7766\n",
            "Epoch 58/500\n",
            "157/804 [====>.........................] - ETA: 1s - loss: 0.4637 - accuracy: 0.7687\n",
            "Epoch 00058: saving model to checkpoints/weights.58.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4555 - accuracy: 0.7766\n",
            "Epoch 59/500\n",
            "365/804 [============>.................] - ETA: 0s - loss: 0.4550 - accuracy: 0.7771\n",
            "Epoch 00059: saving model to checkpoints/weights.59.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4564 - accuracy: 0.7767\n",
            "Epoch 60/500\n",
            "564/804 [====================>.........] - ETA: 0s - loss: 0.4525 - accuracy: 0.7778\n",
            "Epoch 00060: saving model to checkpoints/weights.60.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4558 - accuracy: 0.7765\n",
            "Epoch 61/500\n",
            "745/804 [==========================>...] - ETA: 0s - loss: 0.4569 - accuracy: 0.7762\n",
            "Epoch 00061: saving model to checkpoints/weights.61.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4560 - accuracy: 0.7772\n",
            "Epoch 62/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4552 - accuracy: 0.7766\n",
            "Epoch 63/500\n",
            "134/804 [====>.........................] - ETA: 1s - loss: 0.4609 - accuracy: 0.7724\n",
            "Epoch 00063: saving model to checkpoints/weights.63.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4554 - accuracy: 0.7779\n",
            "Epoch 64/500\n",
            "330/804 [===========>..................] - ETA: 0s - loss: 0.4589 - accuracy: 0.7740\n",
            "Epoch 00064: saving model to checkpoints/weights.64.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4554 - accuracy: 0.7770\n",
            "Epoch 65/500\n",
            "519/804 [==================>...........] - ETA: 0s - loss: 0.4509 - accuracy: 0.7806\n",
            "Epoch 00065: saving model to checkpoints/weights.65.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4551 - accuracy: 0.7775\n",
            "Epoch 66/500\n",
            "733/804 [==========================>...] - ETA: 0s - loss: 0.4549 - accuracy: 0.7781\n",
            "Epoch 00066: saving model to checkpoints/weights.66.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4547 - accuracy: 0.7776\n",
            "Epoch 67/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4573 - accuracy: 0.7769\n",
            "Epoch 68/500\n",
            "122/804 [===>..........................] - ETA: 1s - loss: 0.4576 - accuracy: 0.7787\n",
            "Epoch 00068: saving model to checkpoints/weights.68.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4648 - accuracy: 0.7773\n",
            "Epoch 69/500\n",
            "307/804 [==========>...................] - ETA: 0s - loss: 0.4540 - accuracy: 0.7773\n",
            "Epoch 00069: saving model to checkpoints/weights.69.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4548 - accuracy: 0.7768\n",
            "Epoch 70/500\n",
            "511/804 [==================>...........] - ETA: 0s - loss: 0.4579 - accuracy: 0.7730\n",
            "Epoch 00070: saving model to checkpoints/weights.70.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4539 - accuracy: 0.7780\n",
            "Epoch 71/500\n",
            "704/804 [=========================>....] - ETA: 0s - loss: 0.4576 - accuracy: 0.7746\n",
            "Epoch 00071: saving model to checkpoints/weights.71.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4548 - accuracy: 0.7764\n",
            "Epoch 72/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4541 - accuracy: 0.7770\n",
            "Epoch 73/500\n",
            " 97/804 [==>...........................] - ETA: 1s - loss: 0.4588 - accuracy: 0.7735\n",
            "Epoch 00073: saving model to checkpoints/weights.73.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4543 - accuracy: 0.7773\n",
            "Epoch 74/500\n",
            "285/804 [=========>....................] - ETA: 1s - loss: 0.4629 - accuracy: 0.7696\n",
            "Epoch 00074: saving model to checkpoints/weights.74.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4551 - accuracy: 0.7776\n",
            "Epoch 75/500\n",
            "487/804 [=================>............] - ETA: 0s - loss: 0.4531 - accuracy: 0.7776\n",
            "Epoch 00075: saving model to checkpoints/weights.75.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4544 - accuracy: 0.7776\n",
            "Epoch 76/500\n",
            "698/804 [=========================>....] - ETA: 0s - loss: 0.4549 - accuracy: 0.7766\n",
            "Epoch 00076: saving model to checkpoints/weights.76.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4536 - accuracy: 0.7779\n",
            "Epoch 77/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4543 - accuracy: 0.7779\n",
            "Epoch 78/500\n",
            " 83/804 [==>...........................] - ETA: 1s - loss: 0.4393 - accuracy: 0.7895\n",
            "Epoch 00078: saving model to checkpoints/weights.78.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4545 - accuracy: 0.7773\n",
            "Epoch 79/500\n",
            "274/804 [=========>....................] - ETA: 1s - loss: 0.4526 - accuracy: 0.7806\n",
            "Epoch 00079: saving model to checkpoints/weights.79.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4553 - accuracy: 0.7774\n",
            "Epoch 80/500\n",
            "478/804 [================>.............] - ETA: 0s - loss: 0.4527 - accuracy: 0.7782\n",
            "Epoch 00080: saving model to checkpoints/weights.80.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4544 - accuracy: 0.7774\n",
            "Epoch 81/500\n",
            "663/804 [=======================>......] - ETA: 0s - loss: 0.4543 - accuracy: 0.7763\n",
            "Epoch 00081: saving model to checkpoints/weights.81.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4543 - accuracy: 0.7770\n",
            "Epoch 82/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4544 - accuracy: 0.7780\n",
            "Epoch 83/500\n",
            " 72/804 [=>............................] - ETA: 1s - loss: 0.4614 - accuracy: 0.7678\n",
            "Epoch 00083: saving model to checkpoints/weights.83.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4539 - accuracy: 0.7777\n",
            "Epoch 84/500\n",
            "256/804 [========>.....................] - ETA: 1s - loss: 0.4497 - accuracy: 0.7830\n",
            "Epoch 00084: saving model to checkpoints/weights.84.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4538 - accuracy: 0.7788\n",
            "Epoch 85/500\n",
            "442/804 [===============>..............] - ETA: 0s - loss: 0.4520 - accuracy: 0.7794\n",
            "Epoch 00085: saving model to checkpoints/weights.85.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4535 - accuracy: 0.7780\n",
            "Epoch 86/500\n",
            "657/804 [=======================>......] - ETA: 0s - loss: 0.4521 - accuracy: 0.7791\n",
            "Epoch 00086: saving model to checkpoints/weights.86.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4536 - accuracy: 0.7775\n",
            "Epoch 87/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4536 - accuracy: 0.7778\n",
            "Epoch 88/500\n",
            " 51/804 [>.............................] - ETA: 1s - loss: 0.4494 - accuracy: 0.7819\n",
            "Epoch 00088: saving model to checkpoints/weights.88.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4540 - accuracy: 0.7772\n",
            "Epoch 89/500\n",
            "227/804 [=======>......................] - ETA: 1s - loss: 0.4514 - accuracy: 0.7804\n",
            "Epoch 00089: saving model to checkpoints/weights.89.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4565 - accuracy: 0.7771\n",
            "Epoch 90/500\n",
            "441/804 [===============>..............] - ETA: 0s - loss: 0.4492 - accuracy: 0.7812\n",
            "Epoch 00090: saving model to checkpoints/weights.90.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4531 - accuracy: 0.7778\n",
            "Epoch 91/500\n",
            "628/804 [======================>.......] - ETA: 0s - loss: 0.4528 - accuracy: 0.7792\n",
            "Epoch 00091: saving model to checkpoints/weights.91.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4527 - accuracy: 0.7786\n",
            "Epoch 92/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4531 - accuracy: 0.7779\n",
            "Epoch 93/500\n",
            " 27/804 [>.............................] - ETA: 1s - loss: 0.4323 - accuracy: 0.7882\n",
            "Epoch 00093: saving model to checkpoints/weights.93.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4533 - accuracy: 0.7786\n",
            "Epoch 94/500\n",
            "213/804 [======>.......................] - ETA: 1s - loss: 0.4534 - accuracy: 0.7783\n",
            "Epoch 00094: saving model to checkpoints/weights.94.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4534 - accuracy: 0.7788\n",
            "Epoch 95/500\n",
            "411/804 [==============>...............] - ETA: 0s - loss: 0.4442 - accuracy: 0.7834\n",
            "Epoch 00095: saving model to checkpoints/weights.95.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4534 - accuracy: 0.7778\n",
            "Epoch 96/500\n",
            "613/804 [=====================>........] - ETA: 0s - loss: 0.4542 - accuracy: 0.7771\n",
            "Epoch 00096: saving model to checkpoints/weights.96.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4531 - accuracy: 0.7779\n",
            "Epoch 97/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4535 - accuracy: 0.7781\n",
            "Epoch 98/500\n",
            "  1/804 [..............................] - ETA: 3s - loss: 0.4952 - accuracy: 0.6562\n",
            "Epoch 00098: saving model to checkpoints/weights.98.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4530 - accuracy: 0.7781\n",
            "Epoch 99/500\n",
            "202/804 [======>.......................] - ETA: 1s - loss: 0.4458 - accuracy: 0.7857\n",
            "Epoch 00099: saving model to checkpoints/weights.99.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4534 - accuracy: 0.7778\n",
            "Epoch 100/500\n",
            "389/804 [=============>................] - ETA: 0s - loss: 0.4517 - accuracy: 0.7805\n",
            "Epoch 00100: saving model to checkpoints/weights.100.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4538 - accuracy: 0.7777\n",
            "Epoch 101/500\n",
            "598/804 [=====================>........] - ETA: 0s - loss: 0.4576 - accuracy: 0.7741\n",
            "Epoch 00101: saving model to checkpoints/weights.101.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4543 - accuracy: 0.7781\n",
            "Epoch 102/500\n",
            "782/804 [============================>.] - ETA: 0s - loss: 0.4528 - accuracy: 0.7782\n",
            "Epoch 00102: saving model to checkpoints/weights.102.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4533 - accuracy: 0.7781\n",
            "Epoch 103/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4527 - accuracy: 0.7772\n",
            "Epoch 104/500\n",
            "168/804 [=====>........................] - ETA: 1s - loss: 0.4527 - accuracy: 0.7781\n",
            "Epoch 00104: saving model to checkpoints/weights.104.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4531 - accuracy: 0.7781\n",
            "Epoch 105/500\n",
            "362/804 [============>.................] - ETA: 0s - loss: 0.4541 - accuracy: 0.7781\n",
            "Epoch 00105: saving model to checkpoints/weights.105.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4530 - accuracy: 0.7783\n",
            "Epoch 106/500\n",
            "566/804 [====================>.........] - ETA: 0s - loss: 0.4511 - accuracy: 0.7782\n",
            "Epoch 00106: saving model to checkpoints/weights.106.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4521 - accuracy: 0.7776\n",
            "Epoch 107/500\n",
            "759/804 [===========================>..] - ETA: 0s - loss: 0.4529 - accuracy: 0.7777\n",
            "Epoch 00107: saving model to checkpoints/weights.107.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4535 - accuracy: 0.7775\n",
            "Epoch 108/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4530 - accuracy: 0.7784\n",
            "Epoch 109/500\n",
            "151/804 [====>.........................] - ETA: 1s - loss: 0.4576 - accuracy: 0.7707\n",
            "Epoch 00109: saving model to checkpoints/weights.109.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4525 - accuracy: 0.7783\n",
            "Epoch 110/500\n",
            "344/804 [===========>..................] - ETA: 0s - loss: 0.4538 - accuracy: 0.7761\n",
            "Epoch 00110: saving model to checkpoints/weights.110.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4525 - accuracy: 0.7779\n",
            "Epoch 111/500\n",
            "542/804 [===================>..........] - ETA: 0s - loss: 0.4585 - accuracy: 0.7734\n",
            "Epoch 00111: saving model to checkpoints/weights.111.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4529 - accuracy: 0.7781\n",
            "Epoch 112/500\n",
            "730/804 [==========================>...] - ETA: 0s - loss: 0.4522 - accuracy: 0.7790\n",
            "Epoch 00112: saving model to checkpoints/weights.112.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4529 - accuracy: 0.7787\n",
            "Epoch 113/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4527 - accuracy: 0.7788\n",
            "Epoch 114/500\n",
            "144/804 [====>.........................] - ETA: 1s - loss: 0.4647 - accuracy: 0.7743\n",
            "Epoch 00114: saving model to checkpoints/weights.114.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4533 - accuracy: 0.7774\n",
            "Epoch 115/500\n",
            "334/804 [===========>..................] - ETA: 0s - loss: 0.4566 - accuracy: 0.7741\n",
            "Epoch 00115: saving model to checkpoints/weights.115.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4533 - accuracy: 0.7783\n",
            "Epoch 116/500\n",
            "530/804 [==================>...........] - ETA: 0s - loss: 0.4529 - accuracy: 0.7768\n",
            "Epoch 00116: saving model to checkpoints/weights.116.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4526 - accuracy: 0.7780\n",
            "Epoch 117/500\n",
            "732/804 [==========================>...] - ETA: 0s - loss: 0.4535 - accuracy: 0.7783\n",
            "Epoch 00117: saving model to checkpoints/weights.117.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4530 - accuracy: 0.7785\n",
            "Epoch 118/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4527 - accuracy: 0.7783\n",
            "Epoch 119/500\n",
            "104/804 [==>...........................] - ETA: 1s - loss: 0.4641 - accuracy: 0.7650\n",
            "Epoch 00119: saving model to checkpoints/weights.119.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4523 - accuracy: 0.7781\n",
            "Epoch 120/500\n",
            "307/804 [==========>...................] - ETA: 0s - loss: 0.4570 - accuracy: 0.7739\n",
            "Epoch 00120: saving model to checkpoints/weights.120.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4528 - accuracy: 0.7783\n",
            "Epoch 121/500\n",
            "505/804 [=================>............] - ETA: 0s - loss: 0.4503 - accuracy: 0.7804\n",
            "Epoch 00121: saving model to checkpoints/weights.121.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4522 - accuracy: 0.7780\n",
            "Epoch 122/500\n",
            "699/804 [=========================>....] - ETA: 0s - loss: 0.4521 - accuracy: 0.7784\n",
            "Epoch 00122: saving model to checkpoints/weights.122.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4523 - accuracy: 0.7788\n",
            "Epoch 123/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4527 - accuracy: 0.7781\n",
            "Epoch 124/500\n",
            " 84/804 [==>...........................] - ETA: 1s - loss: 0.4425 - accuracy: 0.7898\n",
            "Epoch 00124: saving model to checkpoints/weights.124.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4532 - accuracy: 0.7787\n",
            "Epoch 125/500\n",
            "297/804 [==========>...................] - ETA: 1s - loss: 0.4575 - accuracy: 0.7754\n",
            "Epoch 00125: saving model to checkpoints/weights.125.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4526 - accuracy: 0.7781\n",
            "Epoch 126/500\n",
            "474/804 [================>.............] - ETA: 0s - loss: 0.4529 - accuracy: 0.7754\n",
            "Epoch 00126: saving model to checkpoints/weights.126.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4530 - accuracy: 0.7785\n",
            "Epoch 127/500\n",
            "692/804 [========================>.....] - ETA: 0s - loss: 0.4506 - accuracy: 0.7791\n",
            "Epoch 00127: saving model to checkpoints/weights.127.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4522 - accuracy: 0.7786\n",
            "Epoch 128/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4524 - accuracy: 0.7783\n",
            "Epoch 129/500\n",
            " 77/804 [=>............................] - ETA: 1s - loss: 0.4624 - accuracy: 0.7768\n",
            "Epoch 00129: saving model to checkpoints/weights.129.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4528 - accuracy: 0.7783\n",
            "Epoch 130/500\n",
            "271/804 [=========>....................] - ETA: 1s - loss: 0.4447 - accuracy: 0.7794\n",
            "Epoch 00130: saving model to checkpoints/weights.130.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4522 - accuracy: 0.7780\n",
            "Epoch 131/500\n",
            "470/804 [================>.............] - ETA: 0s - loss: 0.4581 - accuracy: 0.7793\n",
            "Epoch 00131: saving model to checkpoints/weights.131.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4600 - accuracy: 0.7767\n",
            "Epoch 132/500\n",
            "657/804 [=======================>......] - ETA: 0s - loss: 0.4507 - accuracy: 0.7792\n",
            "Epoch 00132: saving model to checkpoints/weights.132.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4520 - accuracy: 0.7781\n",
            "Epoch 133/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4516 - accuracy: 0.7789\n",
            "Epoch 134/500\n",
            " 51/804 [>.............................] - ETA: 1s - loss: 0.4218 - accuracy: 0.7947\n",
            "Epoch 00134: saving model to checkpoints/weights.134.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4516 - accuracy: 0.7784\n",
            "Epoch 135/500\n",
            "259/804 [========>.....................] - ETA: 1s - loss: 0.4546 - accuracy: 0.7761\n",
            "Epoch 00135: saving model to checkpoints/weights.135.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4514 - accuracy: 0.7785\n",
            "Epoch 136/500\n",
            "459/804 [================>.............] - ETA: 0s - loss: 0.4537 - accuracy: 0.7780\n",
            "Epoch 00136: saving model to checkpoints/weights.136.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4517 - accuracy: 0.7785\n",
            "Epoch 137/500\n",
            "651/804 [=======================>......] - ETA: 0s - loss: 0.4487 - accuracy: 0.7801\n",
            "Epoch 00137: saving model to checkpoints/weights.137.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4517 - accuracy: 0.7784\n",
            "Epoch 138/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4519 - accuracy: 0.7779\n",
            "Epoch 139/500\n",
            " 25/804 [..............................] - ETA: 1s - loss: 0.4486 - accuracy: 0.7750\n",
            "Epoch 00139: saving model to checkpoints/weights.139.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4519 - accuracy: 0.7783\n",
            "Epoch 140/500\n",
            "220/804 [=======>......................] - ETA: 1s - loss: 0.4445 - accuracy: 0.7814\n",
            "Epoch 00140: saving model to checkpoints/weights.140.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4517 - accuracy: 0.7781\n",
            "Epoch 141/500\n",
            "420/804 [==============>...............] - ETA: 0s - loss: 0.4544 - accuracy: 0.7756\n",
            "Epoch 00141: saving model to checkpoints/weights.141.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4527 - accuracy: 0.7779\n",
            "Epoch 142/500\n",
            "627/804 [======================>.......] - ETA: 0s - loss: 0.4535 - accuracy: 0.7782\n",
            "Epoch 00142: saving model to checkpoints/weights.142.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4542 - accuracy: 0.7779\n",
            "Epoch 143/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4513 - accuracy: 0.7785\n",
            "Epoch 144/500\n",
            " 25/804 [..............................] - ETA: 1s - loss: 0.4365 - accuracy: 0.7837\n",
            "Epoch 00144: saving model to checkpoints/weights.144.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4518 - accuracy: 0.7785\n",
            "Epoch 145/500\n",
            "205/804 [======>.......................] - ETA: 1s - loss: 0.4489 - accuracy: 0.7776\n",
            "Epoch 00145: saving model to checkpoints/weights.145.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4511 - accuracy: 0.7787\n",
            "Epoch 146/500\n",
            "399/804 [=============>................] - ETA: 0s - loss: 0.4552 - accuracy: 0.7736\n",
            "Epoch 00146: saving model to checkpoints/weights.146.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4515 - accuracy: 0.7785\n",
            "Epoch 147/500\n",
            "589/804 [====================>.........] - ETA: 0s - loss: 0.4504 - accuracy: 0.7790\n",
            "Epoch 00147: saving model to checkpoints/weights.147.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4515 - accuracy: 0.7784\n",
            "Epoch 148/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4516 - accuracy: 0.7785\n",
            "Epoch 149/500\n",
            "  1/804 [..............................] - ETA: 3s - loss: 0.4072 - accuracy: 0.7812\n",
            "Epoch 00149: saving model to checkpoints/weights.149.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4518 - accuracy: 0.7785\n",
            "Epoch 150/500\n",
            "201/804 [======>.......................] - ETA: 1s - loss: 0.4478 - accuracy: 0.7744\n",
            "Epoch 00150: saving model to checkpoints/weights.150.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4518 - accuracy: 0.7784\n",
            "Epoch 151/500\n",
            "391/804 [=============>................] - ETA: 0s - loss: 0.4427 - accuracy: 0.7844\n",
            "Epoch 00151: saving model to checkpoints/weights.151.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4524 - accuracy: 0.7779\n",
            "Epoch 152/500\n",
            "585/804 [====================>.........] - ETA: 0s - loss: 0.4495 - accuracy: 0.7808\n",
            "Epoch 00152: saving model to checkpoints/weights.152.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4529 - accuracy: 0.7789\n",
            "Epoch 153/500\n",
            "787/804 [============================>.] - ETA: 0s - loss: 0.4534 - accuracy: 0.7777\n",
            "Epoch 00153: saving model to checkpoints/weights.153.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4527 - accuracy: 0.7785\n",
            "Epoch 154/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4518 - accuracy: 0.7790\n",
            "Epoch 155/500\n",
            "171/804 [=====>........................] - ETA: 1s - loss: 0.4509 - accuracy: 0.7787\n",
            "Epoch 00155: saving model to checkpoints/weights.155.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4522 - accuracy: 0.7784\n",
            "Epoch 156/500\n",
            "355/804 [============>.................] - ETA: 0s - loss: 0.4544 - accuracy: 0.7732\n",
            "Epoch 00156: saving model to checkpoints/weights.156.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4517 - accuracy: 0.7780\n",
            "Epoch 157/500\n",
            "563/804 [====================>.........] - ETA: 0s - loss: 0.4499 - accuracy: 0.7801\n",
            "Epoch 00157: saving model to checkpoints/weights.157.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4519 - accuracy: 0.7786\n",
            "Epoch 158/500\n",
            "750/804 [==========================>...] - ETA: 0s - loss: 0.4508 - accuracy: 0.7785\n",
            "Epoch 00158: saving model to checkpoints/weights.158.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4520 - accuracy: 0.7778\n",
            "Epoch 159/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4550 - accuracy: 0.7788\n",
            "Epoch 160/500\n",
            "145/804 [====>.........................] - ETA: 1s - loss: 0.4449 - accuracy: 0.7806\n",
            "Epoch 00160: saving model to checkpoints/weights.160.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4556 - accuracy: 0.7783\n",
            "Epoch 161/500\n",
            "351/804 [============>.................] - ETA: 0s - loss: 0.4500 - accuracy: 0.7764\n",
            "Epoch 00161: saving model to checkpoints/weights.161.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4514 - accuracy: 0.7787\n",
            "Epoch 162/500\n",
            "541/804 [===================>..........] - ETA: 0s - loss: 0.4498 - accuracy: 0.7797\n",
            "Epoch 00162: saving model to checkpoints/weights.162.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4509 - accuracy: 0.7785\n",
            "Epoch 163/500\n",
            "727/804 [==========================>...] - ETA: 0s - loss: 0.4524 - accuracy: 0.7782\n",
            "Epoch 00163: saving model to checkpoints/weights.163.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4512 - accuracy: 0.7785\n",
            "Epoch 164/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4510 - accuracy: 0.7782\n",
            "Epoch 165/500\n",
            "123/804 [===>..........................] - ETA: 1s - loss: 0.4437 - accuracy: 0.7795\n",
            "Epoch 00165: saving model to checkpoints/weights.165.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4507 - accuracy: 0.7787\n",
            "Epoch 166/500\n",
            "325/804 [===========>..................] - ETA: 1s - loss: 0.4464 - accuracy: 0.7780\n",
            "Epoch 00166: saving model to checkpoints/weights.166.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4511 - accuracy: 0.7776\n",
            "Epoch 167/500\n",
            "531/804 [==================>...........] - ETA: 0s - loss: 0.4496 - accuracy: 0.7804\n",
            "Epoch 00167: saving model to checkpoints/weights.167.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4520 - accuracy: 0.7785\n",
            "Epoch 168/500\n",
            "709/804 [=========================>....] - ETA: 0s - loss: 0.4523 - accuracy: 0.7791\n",
            "Epoch 00168: saving model to checkpoints/weights.168.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4524 - accuracy: 0.7784\n",
            "Epoch 169/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4517 - accuracy: 0.7789\n",
            "Epoch 170/500\n",
            "118/804 [===>..........................] - ETA: 1s - loss: 0.4521 - accuracy: 0.7823\n",
            "Epoch 00170: saving model to checkpoints/weights.170.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4518 - accuracy: 0.7783\n",
            "Epoch 171/500\n",
            "316/804 [==========>...................] - ETA: 1s - loss: 0.4480 - accuracy: 0.7776\n",
            "Epoch 00171: saving model to checkpoints/weights.171.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4522 - accuracy: 0.7776\n",
            "Epoch 172/500\n",
            "492/804 [=================>............] - ETA: 0s - loss: 0.4542 - accuracy: 0.7800\n",
            "Epoch 00172: saving model to checkpoints/weights.172.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4528 - accuracy: 0.7788\n",
            "Epoch 173/500\n",
            "699/804 [=========================>....] - ETA: 0s - loss: 0.4512 - accuracy: 0.7791\n",
            "Epoch 00173: saving model to checkpoints/weights.173.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4515 - accuracy: 0.7791\n",
            "Epoch 174/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4511 - accuracy: 0.7777\n",
            "Epoch 175/500\n",
            " 80/804 [=>............................] - ETA: 1s - loss: 0.4471 - accuracy: 0.7793\n",
            "Epoch 00175: saving model to checkpoints/weights.175.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4516 - accuracy: 0.7785\n",
            "Epoch 176/500\n",
            "285/804 [=========>....................] - ETA: 1s - loss: 0.4533 - accuracy: 0.7793\n",
            "Epoch 00176: saving model to checkpoints/weights.176.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4523 - accuracy: 0.7786\n",
            "Epoch 177/500\n",
            "482/804 [================>.............] - ETA: 0s - loss: 0.4498 - accuracy: 0.7801\n",
            "Epoch 00177: saving model to checkpoints/weights.177.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4525 - accuracy: 0.7784\n",
            "Epoch 178/500\n",
            "682/804 [========================>.....] - ETA: 0s - loss: 0.4520 - accuracy: 0.7785\n",
            "Epoch 00178: saving model to checkpoints/weights.178.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4518 - accuracy: 0.7794\n",
            "Epoch 179/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4516 - accuracy: 0.7790\n",
            "Epoch 180/500\n",
            " 69/804 [=>............................] - ETA: 1s - loss: 0.4513 - accuracy: 0.7803\n",
            "Epoch 00180: saving model to checkpoints/weights.180.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4513 - accuracy: 0.7781\n",
            "Epoch 181/500\n",
            "278/804 [=========>....................] - ETA: 1s - loss: 0.4552 - accuracy: 0.7751\n",
            "Epoch 00181: saving model to checkpoints/weights.181.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4514 - accuracy: 0.7783\n",
            "Epoch 182/500\n",
            "471/804 [================>.............] - ETA: 0s - loss: 0.4528 - accuracy: 0.7788\n",
            "Epoch 00182: saving model to checkpoints/weights.182.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4521 - accuracy: 0.7785\n",
            "Epoch 183/500\n",
            "659/804 [=======================>......] - ETA: 0s - loss: 0.4490 - accuracy: 0.7794\n",
            "Epoch 00183: saving model to checkpoints/weights.183.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4516 - accuracy: 0.7782\n",
            "Epoch 184/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4513 - accuracy: 0.7792\n",
            "Epoch 185/500\n",
            " 52/804 [>.............................] - ETA: 1s - loss: 0.4614 - accuracy: 0.7722\n",
            "Epoch 00185: saving model to checkpoints/weights.185.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4510 - accuracy: 0.7786\n",
            "Epoch 186/500\n",
            "244/804 [========>.....................] - ETA: 1s - loss: 0.4503 - accuracy: 0.7798\n",
            "Epoch 00186: saving model to checkpoints/weights.186.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4509 - accuracy: 0.7790\n",
            "Epoch 187/500\n",
            "445/804 [===============>..............] - ETA: 0s - loss: 0.4514 - accuracy: 0.7798\n",
            "Epoch 00187: saving model to checkpoints/weights.187.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4520 - accuracy: 0.7783\n",
            "Epoch 188/500\n",
            "640/804 [======================>.......] - ETA: 0s - loss: 0.4550 - accuracy: 0.7763\n",
            "Epoch 00188: saving model to checkpoints/weights.188.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4547 - accuracy: 0.7781\n",
            "Epoch 189/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4513 - accuracy: 0.7785\n",
            "Epoch 190/500\n",
            " 20/804 [..............................] - ETA: 2s - loss: 0.4440 - accuracy: 0.7828\n",
            "Epoch 00190: saving model to checkpoints/weights.190.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4518 - accuracy: 0.7785\n",
            "Epoch 191/500\n",
            "218/804 [=======>......................] - ETA: 1s - loss: 0.4461 - accuracy: 0.7845\n",
            "Epoch 00191: saving model to checkpoints/weights.191.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4511 - accuracy: 0.7789\n",
            "Epoch 192/500\n",
            "431/804 [===============>..............] - ETA: 0s - loss: 0.4490 - accuracy: 0.7790\n",
            "Epoch 00192: saving model to checkpoints/weights.192.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4513 - accuracy: 0.7782\n",
            "Epoch 193/500\n",
            "615/804 [=====================>........] - ETA: 0s - loss: 0.4496 - accuracy: 0.7791\n",
            "Epoch 00193: saving model to checkpoints/weights.193.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4524 - accuracy: 0.7782\n",
            "Epoch 194/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4530 - accuracy: 0.7787\n",
            "Epoch 195/500\n",
            " 22/804 [..............................] - ETA: 1s - loss: 0.4390 - accuracy: 0.7770\n",
            "Epoch 00195: saving model to checkpoints/weights.195.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4508 - accuracy: 0.7787\n",
            "Epoch 196/500\n",
            "213/804 [======>.......................] - ETA: 1s - loss: 0.4449 - accuracy: 0.7835\n",
            "Epoch 00196: saving model to checkpoints/weights.196.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4510 - accuracy: 0.7778\n",
            "Epoch 197/500\n",
            "395/804 [=============>................] - ETA: 0s - loss: 0.4484 - accuracy: 0.7786\n",
            "Epoch 00197: saving model to checkpoints/weights.197.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4514 - accuracy: 0.7790\n",
            "Epoch 198/500\n",
            "609/804 [=====================>........] - ETA: 0s - loss: 0.4526 - accuracy: 0.7801\n",
            "Epoch 00198: saving model to checkpoints/weights.198.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4545 - accuracy: 0.7789\n",
            "Epoch 199/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4505 - accuracy: 0.7794\n",
            "Epoch 200/500\n",
            "  1/804 [..............................] - ETA: 7s - loss: 0.4789 - accuracy: 0.7188\n",
            "Epoch 00200: saving model to checkpoints/weights.200.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4509 - accuracy: 0.7783\n",
            "Epoch 201/500\n",
            "185/804 [=====>........................] - ETA: 1s - loss: 0.4339 - accuracy: 0.7877\n",
            "Epoch 00201: saving model to checkpoints/weights.201.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4517 - accuracy: 0.7792\n",
            "Epoch 202/500\n",
            "383/804 [=============>................] - ETA: 0s - loss: 0.4470 - accuracy: 0.7822\n",
            "Epoch 00202: saving model to checkpoints/weights.202.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4509 - accuracy: 0.7788\n",
            "Epoch 203/500\n",
            "576/804 [====================>.........] - ETA: 0s - loss: 0.4520 - accuracy: 0.7779\n",
            "Epoch 00203: saving model to checkpoints/weights.203.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4507 - accuracy: 0.7781\n",
            "Epoch 204/500\n",
            "769/804 [===========================>..] - ETA: 0s - loss: 0.4516 - accuracy: 0.7781\n",
            "Epoch 00204: saving model to checkpoints/weights.204.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4514 - accuracy: 0.7779\n",
            "Epoch 205/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4540 - accuracy: 0.7789\n",
            "Epoch 206/500\n",
            "174/804 [=====>........................] - ETA: 1s - loss: 0.4650 - accuracy: 0.7714\n",
            "Epoch 00206: saving model to checkpoints/weights.206.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4574 - accuracy: 0.7783\n",
            "Epoch 207/500\n",
            "374/804 [============>.................] - ETA: 0s - loss: 0.4520 - accuracy: 0.7793\n",
            "Epoch 00207: saving model to checkpoints/weights.207.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4523 - accuracy: 0.7785\n",
            "Epoch 208/500\n",
            "553/804 [===================>..........] - ETA: 0s - loss: 0.4489 - accuracy: 0.7792\n",
            "Epoch 00208: saving model to checkpoints/weights.208.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4506 - accuracy: 0.7782\n",
            "Epoch 209/500\n",
            "765/804 [===========================>..] - ETA: 0s - loss: 0.4496 - accuracy: 0.7800\n",
            "Epoch 00209: saving model to checkpoints/weights.209.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4502 - accuracy: 0.7796\n",
            "Epoch 210/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4504 - accuracy: 0.7787\n",
            "Epoch 211/500\n",
            "143/804 [====>.........................] - ETA: 1s - loss: 0.4350 - accuracy: 0.7920\n",
            "Epoch 00211: saving model to checkpoints/weights.211.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4505 - accuracy: 0.7782\n",
            "Epoch 212/500\n",
            "344/804 [===========>..................] - ETA: 0s - loss: 0.4496 - accuracy: 0.7787\n",
            "Epoch 00212: saving model to checkpoints/weights.212.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4525 - accuracy: 0.7785\n",
            "Epoch 213/500\n",
            "544/804 [===================>..........] - ETA: 0s - loss: 0.4496 - accuracy: 0.7810\n",
            "Epoch 00213: saving model to checkpoints/weights.213.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4513 - accuracy: 0.7784\n",
            "Epoch 214/500\n",
            "746/804 [==========================>...] - ETA: 0s - loss: 0.4507 - accuracy: 0.7779\n",
            "Epoch 00214: saving model to checkpoints/weights.214.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4506 - accuracy: 0.7782\n",
            "Epoch 215/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4508 - accuracy: 0.7784\n",
            "Epoch 216/500\n",
            "117/804 [===>..........................] - ETA: 1s - loss: 0.4476 - accuracy: 0.7772\n",
            "Epoch 00216: saving model to checkpoints/weights.216.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4506 - accuracy: 0.7785\n",
            "Epoch 217/500\n",
            "313/804 [==========>...................] - ETA: 1s - loss: 0.4453 - accuracy: 0.7838\n",
            "Epoch 00217: saving model to checkpoints/weights.217.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4508 - accuracy: 0.7780\n",
            "Epoch 218/500\n",
            "515/804 [==================>...........] - ETA: 0s - loss: 0.4483 - accuracy: 0.7805\n",
            "Epoch 00218: saving model to checkpoints/weights.218.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4510 - accuracy: 0.7788\n",
            "Epoch 219/500\n",
            "721/804 [=========================>....] - ETA: 0s - loss: 0.4518 - accuracy: 0.7767\n",
            "Epoch 00219: saving model to checkpoints/weights.219.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4509 - accuracy: 0.7781\n",
            "Epoch 220/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4554 - accuracy: 0.7776\n",
            "Epoch 221/500\n",
            "118/804 [===>..........................] - ETA: 1s - loss: 0.4469 - accuracy: 0.7786\n",
            "Epoch 00221: saving model to checkpoints/weights.221.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4507 - accuracy: 0.7783\n",
            "Epoch 222/500\n",
            "295/804 [==========>...................] - ETA: 1s - loss: 0.4448 - accuracy: 0.7849\n",
            "Epoch 00222: saving model to checkpoints/weights.222.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4506 - accuracy: 0.7792\n",
            "Epoch 223/500\n",
            "491/804 [=================>............] - ETA: 0s - loss: 0.4528 - accuracy: 0.7774\n",
            "Epoch 00223: saving model to checkpoints/weights.223.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4503 - accuracy: 0.7788\n",
            "Epoch 224/500\n",
            "684/804 [========================>.....] - ETA: 0s - loss: 0.4528 - accuracy: 0.7778\n",
            "Epoch 00224: saving model to checkpoints/weights.224.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4506 - accuracy: 0.7789\n",
            "Epoch 225/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4508 - accuracy: 0.7791\n",
            "Epoch 226/500\n",
            " 76/804 [=>............................] - ETA: 1s - loss: 0.4505 - accuracy: 0.7710\n",
            "Epoch 00226: saving model to checkpoints/weights.226.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4507 - accuracy: 0.7787\n",
            "Epoch 227/500\n",
            "272/804 [=========>....................] - ETA: 1s - loss: 0.4468 - accuracy: 0.7831\n",
            "Epoch 00227: saving model to checkpoints/weights.227.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4507 - accuracy: 0.7783\n",
            "Epoch 228/500\n",
            "479/804 [================>.............] - ETA: 0s - loss: 0.4484 - accuracy: 0.7780\n",
            "Epoch 00228: saving model to checkpoints/weights.228.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4511 - accuracy: 0.7788\n",
            "Epoch 229/500\n",
            "685/804 [========================>.....] - ETA: 0s - loss: 0.4501 - accuracy: 0.7805\n",
            "Epoch 00229: saving model to checkpoints/weights.229.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4506 - accuracy: 0.7793\n",
            "Epoch 230/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4514 - accuracy: 0.7785\n",
            "Epoch 231/500\n",
            " 70/804 [=>............................] - ETA: 1s - loss: 0.4609 - accuracy: 0.7665\n",
            "Epoch 00231: saving model to checkpoints/weights.231.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4576 - accuracy: 0.7783\n",
            "Epoch 232/500\n",
            "266/804 [========>.....................] - ETA: 1s - loss: 0.4574 - accuracy: 0.7775\n",
            "Epoch 00232: saving model to checkpoints/weights.232.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4515 - accuracy: 0.7780\n",
            "Epoch 233/500\n",
            "450/804 [===============>..............] - ETA: 0s - loss: 0.4521 - accuracy: 0.7778\n",
            "Epoch 00233: saving model to checkpoints/weights.233.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4502 - accuracy: 0.7787\n",
            "Epoch 234/500\n",
            "644/804 [=======================>......] - ETA: 0s - loss: 0.4500 - accuracy: 0.7786\n",
            "Epoch 00234: saving model to checkpoints/weights.234.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4509 - accuracy: 0.7784\n",
            "Epoch 235/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4550 - accuracy: 0.7791\n",
            "Epoch 236/500\n",
            " 46/804 [>.............................] - ETA: 1s - loss: 0.4508 - accuracy: 0.7772\n",
            "Epoch 00236: saving model to checkpoints/weights.236.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4507 - accuracy: 0.7790\n",
            "Epoch 237/500\n",
            "244/804 [========>.....................] - ETA: 1s - loss: 0.4447 - accuracy: 0.7800\n",
            "Epoch 00237: saving model to checkpoints/weights.237.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4509 - accuracy: 0.7786\n",
            "Epoch 238/500\n",
            "429/804 [===============>..............] - ETA: 0s - loss: 0.4474 - accuracy: 0.7826\n",
            "Epoch 00238: saving model to checkpoints/weights.238.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4512 - accuracy: 0.7792\n",
            "Epoch 239/500\n",
            "638/804 [======================>.......] - ETA: 0s - loss: 0.4515 - accuracy: 0.7778\n",
            "Epoch 00239: saving model to checkpoints/weights.239.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4515 - accuracy: 0.7780\n",
            "Epoch 240/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4510 - accuracy: 0.7786\n",
            "Epoch 241/500\n",
            " 23/804 [..............................] - ETA: 1s - loss: 0.4426 - accuracy: 0.7894\n",
            "Epoch 00241: saving model to checkpoints/weights.241.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4521 - accuracy: 0.7780\n",
            "Epoch 242/500\n",
            "232/804 [=======>......................] - ETA: 1s - loss: 0.4448 - accuracy: 0.7831\n",
            "Epoch 00242: saving model to checkpoints/weights.242.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4507 - accuracy: 0.7789\n",
            "Epoch 243/500\n",
            "431/804 [===============>..............] - ETA: 0s - loss: 0.4508 - accuracy: 0.7775\n",
            "Epoch 00243: saving model to checkpoints/weights.243.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4505 - accuracy: 0.7787\n",
            "Epoch 244/500\n",
            "606/804 [=====================>........] - ETA: 0s - loss: 0.4532 - accuracy: 0.7760\n",
            "Epoch 00244: saving model to checkpoints/weights.244.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4507 - accuracy: 0.7782\n",
            "Epoch 245/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4505 - accuracy: 0.7789\n",
            "Epoch 246/500\n",
            "  1/804 [..............................] - ETA: 6s - loss: 0.3749 - accuracy: 0.7812\n",
            "Epoch 00246: saving model to checkpoints/weights.246.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4507 - accuracy: 0.7785\n",
            "Epoch 247/500\n",
            "195/804 [======>.......................] - ETA: 1s - loss: 0.4495 - accuracy: 0.7806\n",
            "Epoch 00247: saving model to checkpoints/weights.247.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4512 - accuracy: 0.7789\n",
            "Epoch 248/500\n",
            "394/804 [=============>................] - ETA: 0s - loss: 0.4512 - accuracy: 0.7774\n",
            "Epoch 00248: saving model to checkpoints/weights.248.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4513 - accuracy: 0.7782\n",
            "Epoch 249/500\n",
            "607/804 [=====================>........] - ETA: 0s - loss: 0.4530 - accuracy: 0.7768\n",
            "Epoch 00249: saving model to checkpoints/weights.249.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4510 - accuracy: 0.7789\n",
            "Epoch 250/500\n",
            "789/804 [============================>.] - ETA: 0s - loss: 0.4509 - accuracy: 0.7785\n",
            "Epoch 00250: saving model to checkpoints/weights.250.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4506 - accuracy: 0.7787\n",
            "Epoch 251/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4510 - accuracy: 0.7786\n",
            "Epoch 252/500\n",
            "183/804 [=====>........................] - ETA: 1s - loss: 0.4398 - accuracy: 0.7797\n",
            "Epoch 00252: saving model to checkpoints/weights.252.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4506 - accuracy: 0.7788\n",
            "Epoch 253/500\n",
            "373/804 [============>.................] - ETA: 0s - loss: 0.4475 - accuracy: 0.7806\n",
            "Epoch 00253: saving model to checkpoints/weights.253.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4503 - accuracy: 0.7793\n",
            "Epoch 254/500\n",
            "571/804 [====================>.........] - ETA: 0s - loss: 0.4510 - accuracy: 0.7775\n",
            "Epoch 00254: saving model to checkpoints/weights.254.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4507 - accuracy: 0.7790\n",
            "Epoch 255/500\n",
            "760/804 [===========================>..] - ETA: 0s - loss: 0.4802 - accuracy: 0.7790\n",
            "Epoch 00255: saving model to checkpoints/weights.255.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4790 - accuracy: 0.7783\n",
            "Epoch 256/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4505 - accuracy: 0.7785\n",
            "Epoch 257/500\n",
            "161/804 [=====>........................] - ETA: 1s - loss: 0.4526 - accuracy: 0.7809\n",
            "Epoch 00257: saving model to checkpoints/weights.257.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4500 - accuracy: 0.7794\n",
            "Epoch 258/500\n",
            "370/804 [============>.................] - ETA: 0s - loss: 0.4512 - accuracy: 0.7766\n",
            "Epoch 00258: saving model to checkpoints/weights.258.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4500 - accuracy: 0.7788\n",
            "Epoch 259/500\n",
            "565/804 [====================>.........] - ETA: 0s - loss: 0.4497 - accuracy: 0.7792\n",
            "Epoch 00259: saving model to checkpoints/weights.259.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4504 - accuracy: 0.7783\n",
            "Epoch 260/500\n",
            "755/804 [===========================>..] - ETA: 0s - loss: 0.4498 - accuracy: 0.7798\n",
            "Epoch 00260: saving model to checkpoints/weights.260.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4507 - accuracy: 0.7791\n",
            "Epoch 261/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4500 - accuracy: 0.7793\n",
            "Epoch 262/500\n",
            "143/804 [====>.........................] - ETA: 1s - loss: 0.4503 - accuracy: 0.7806\n",
            "Epoch 00262: saving model to checkpoints/weights.262.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4499 - accuracy: 0.7791\n",
            "Epoch 263/500\n",
            "350/804 [============>.................] - ETA: 0s - loss: 0.4467 - accuracy: 0.7835\n",
            "Epoch 00263: saving model to checkpoints/weights.263.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4510 - accuracy: 0.7787\n",
            "Epoch 264/500\n",
            "528/804 [==================>...........] - ETA: 0s - loss: 0.4507 - accuracy: 0.7786\n",
            "Epoch 00264: saving model to checkpoints/weights.264.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4511 - accuracy: 0.7783\n",
            "Epoch 265/500\n",
            "731/804 [==========================>...] - ETA: 0s - loss: 0.4502 - accuracy: 0.7801\n",
            "Epoch 00265: saving model to checkpoints/weights.265.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4505 - accuracy: 0.7793\n",
            "Epoch 266/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4512 - accuracy: 0.7783\n",
            "Epoch 267/500\n",
            "116/804 [===>..........................] - ETA: 1s - loss: 0.4432 - accuracy: 0.7928\n",
            "Epoch 00267: saving model to checkpoints/weights.267.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4507 - accuracy: 0.7785\n",
            "Epoch 268/500\n",
            "323/804 [===========>..................] - ETA: 1s - loss: 0.4511 - accuracy: 0.7779\n",
            "Epoch 00268: saving model to checkpoints/weights.268.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4513 - accuracy: 0.7779\n",
            "Epoch 269/500\n",
            "528/804 [==================>...........] - ETA: 0s - loss: 0.4481 - accuracy: 0.7793\n",
            "Epoch 00269: saving model to checkpoints/weights.269.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4509 - accuracy: 0.7785\n",
            "Epoch 270/500\n",
            "722/804 [=========================>....] - ETA: 0s - loss: 0.4513 - accuracy: 0.7782\n",
            "Epoch 00270: saving model to checkpoints/weights.270.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4507 - accuracy: 0.7782\n",
            "Epoch 271/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4500 - accuracy: 0.7787\n",
            "Epoch 272/500\n",
            " 92/804 [==>...........................] - ETA: 1s - loss: 0.4526 - accuracy: 0.7816\n",
            "Epoch 00272: saving model to checkpoints/weights.272.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4509 - accuracy: 0.7787\n",
            "Epoch 273/500\n",
            "299/804 [==========>...................] - ETA: 1s - loss: 0.4489 - accuracy: 0.7822\n",
            "Epoch 00273: saving model to checkpoints/weights.273.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4504 - accuracy: 0.7795\n",
            "Epoch 274/500\n",
            "503/804 [=================>............] - ETA: 0s - loss: 0.4511 - accuracy: 0.7793\n",
            "Epoch 00274: saving model to checkpoints/weights.274.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4514 - accuracy: 0.7787\n",
            "Epoch 275/500\n",
            "685/804 [========================>.....] - ETA: 0s - loss: 0.4503 - accuracy: 0.7794\n",
            "Epoch 00275: saving model to checkpoints/weights.275.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4511 - accuracy: 0.7788\n",
            "Epoch 276/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4517 - accuracy: 0.7790\n",
            "Epoch 277/500\n",
            " 88/804 [==>...........................] - ETA: 1s - loss: 0.4496 - accuracy: 0.7869\n",
            "Epoch 00277: saving model to checkpoints/weights.277.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4526 - accuracy: 0.7794\n",
            "Epoch 278/500\n",
            "280/804 [=========>....................] - ETA: 1s - loss: 0.4576 - accuracy: 0.7741\n",
            "Epoch 00278: saving model to checkpoints/weights.278.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4541 - accuracy: 0.7789\n",
            "Epoch 279/500\n",
            "486/804 [=================>............] - ETA: 0s - loss: 0.4626 - accuracy: 0.7760\n",
            "Epoch 00279: saving model to checkpoints/weights.279.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4556 - accuracy: 0.7787\n",
            "Epoch 280/500\n",
            "671/804 [========================>.....] - ETA: 0s - loss: 0.4521 - accuracy: 0.7781\n",
            "Epoch 00280: saving model to checkpoints/weights.280.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4509 - accuracy: 0.7788\n",
            "Epoch 281/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4504 - accuracy: 0.7788\n",
            "Epoch 282/500\n",
            " 67/804 [=>............................] - ETA: 1s - loss: 0.4538 - accuracy: 0.7677\n",
            "Epoch 00282: saving model to checkpoints/weights.282.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4503 - accuracy: 0.7781\n",
            "Epoch 283/500\n",
            "267/804 [========>.....................] - ETA: 1s - loss: 0.4487 - accuracy: 0.7803\n",
            "Epoch 00283: saving model to checkpoints/weights.283.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4509 - accuracy: 0.7787\n",
            "Epoch 284/500\n",
            "463/804 [================>.............] - ETA: 0s - loss: 0.4504 - accuracy: 0.7771\n",
            "Epoch 00284: saving model to checkpoints/weights.284.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4505 - accuracy: 0.7786\n",
            "Epoch 285/500\n",
            "652/804 [=======================>......] - ETA: 0s - loss: 0.4468 - accuracy: 0.7793\n",
            "Epoch 00285: saving model to checkpoints/weights.285.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4500 - accuracy: 0.7788\n",
            "Epoch 286/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4509 - accuracy: 0.7783\n",
            "Epoch 287/500\n",
            " 48/804 [>.............................] - ETA: 1s - loss: 0.4502 - accuracy: 0.7715\n",
            "Epoch 00287: saving model to checkpoints/weights.287.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4504 - accuracy: 0.7792\n",
            "Epoch 288/500\n",
            "241/804 [=======>......................] - ETA: 1s - loss: 0.4489 - accuracy: 0.7829\n",
            "Epoch 00288: saving model to checkpoints/weights.288.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4507 - accuracy: 0.7789\n",
            "Epoch 289/500\n",
            "436/804 [===============>..............] - ETA: 0s - loss: 0.4460 - accuracy: 0.7798\n",
            "Epoch 00289: saving model to checkpoints/weights.289.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4502 - accuracy: 0.7785\n",
            "Epoch 290/500\n",
            "644/804 [=======================>......] - ETA: 0s - loss: 0.4548 - accuracy: 0.7754\n",
            "Epoch 00290: saving model to checkpoints/weights.290.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4679 - accuracy: 0.7784\n",
            "Epoch 291/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4504 - accuracy: 0.7792\n",
            "Epoch 292/500\n",
            " 23/804 [..............................] - ETA: 1s - loss: 0.4393 - accuracy: 0.7908\n",
            "Epoch 00292: saving model to checkpoints/weights.292.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4497 - accuracy: 0.7792\n",
            "Epoch 293/500\n",
            "226/804 [=======>......................] - ETA: 1s - loss: 0.4448 - accuracy: 0.7804\n",
            "Epoch 00293: saving model to checkpoints/weights.293.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4497 - accuracy: 0.7792\n",
            "Epoch 294/500\n",
            "421/804 [==============>...............] - ETA: 0s - loss: 0.4489 - accuracy: 0.7803\n",
            "Epoch 00294: saving model to checkpoints/weights.294.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4497 - accuracy: 0.7789\n",
            "Epoch 295/500\n",
            "612/804 [=====================>........] - ETA: 0s - loss: 0.4481 - accuracy: 0.7794\n",
            "Epoch 00295: saving model to checkpoints/weights.295.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4495 - accuracy: 0.7786\n",
            "Epoch 296/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4500 - accuracy: 0.7795\n",
            "Epoch 297/500\n",
            "  1/804 [..............................] - ETA: 10s - loss: 0.4494 - accuracy: 0.7812\n",
            "Epoch 00297: saving model to checkpoints/weights.297.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4506 - accuracy: 0.7787\n",
            "Epoch 298/500\n",
            "200/804 [======>.......................] - ETA: 1s - loss: 0.4509 - accuracy: 0.7767\n",
            "Epoch 00298: saving model to checkpoints/weights.298.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4502 - accuracy: 0.7790\n",
            "Epoch 299/500\n",
            "391/804 [=============>................] - ETA: 0s - loss: 0.4494 - accuracy: 0.7777\n",
            "Epoch 00299: saving model to checkpoints/weights.299.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4509 - accuracy: 0.7792\n",
            "Epoch 300/500\n",
            "586/804 [====================>.........] - ETA: 0s - loss: 0.4484 - accuracy: 0.7787\n",
            "Epoch 00300: saving model to checkpoints/weights.300.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4502 - accuracy: 0.7783\n",
            "Epoch 301/500\n",
            "793/804 [============================>.] - ETA: 0s - loss: 0.4598 - accuracy: 0.7783\n",
            "Epoch 00301: saving model to checkpoints/weights.301.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4595 - accuracy: 0.7783\n",
            "Epoch 302/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4517 - accuracy: 0.7788\n",
            "Epoch 303/500\n",
            "184/804 [=====>........................] - ETA: 1s - loss: 0.4507 - accuracy: 0.7779\n",
            "Epoch 00303: saving model to checkpoints/weights.303.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4496 - accuracy: 0.7787\n",
            "Epoch 304/500\n",
            "388/804 [=============>................] - ETA: 0s - loss: 0.4450 - accuracy: 0.7789\n",
            "Epoch 00304: saving model to checkpoints/weights.304.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4497 - accuracy: 0.7788\n",
            "Epoch 305/500\n",
            "569/804 [====================>.........] - ETA: 0s - loss: 0.4485 - accuracy: 0.7810\n",
            "Epoch 00305: saving model to checkpoints/weights.305.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4500 - accuracy: 0.7792\n",
            "Epoch 306/500\n",
            "765/804 [===========================>..] - ETA: 0s - loss: 0.4503 - accuracy: 0.7800\n",
            "Epoch 00306: saving model to checkpoints/weights.306.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4505 - accuracy: 0.7798\n",
            "Epoch 307/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4506 - accuracy: 0.7786\n",
            "Epoch 308/500\n",
            "163/804 [=====>........................] - ETA: 1s - loss: 0.4509 - accuracy: 0.7763\n",
            "Epoch 00308: saving model to checkpoints/weights.308.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4502 - accuracy: 0.7784\n",
            "Epoch 309/500\n",
            "346/804 [===========>..................] - ETA: 1s - loss: 0.4499 - accuracy: 0.7769\n",
            "Epoch 00309: saving model to checkpoints/weights.309.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4514 - accuracy: 0.7788\n",
            "Epoch 310/500\n",
            "548/804 [===================>..........] - ETA: 0s - loss: 0.4509 - accuracy: 0.7787\n",
            "Epoch 00310: saving model to checkpoints/weights.310.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4509 - accuracy: 0.7793\n",
            "Epoch 311/500\n",
            "751/804 [===========================>..] - ETA: 0s - loss: 0.4496 - accuracy: 0.7790\n",
            "Epoch 00311: saving model to checkpoints/weights.311.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4513 - accuracy: 0.7785\n",
            "Epoch 312/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4532 - accuracy: 0.7791\n",
            "Epoch 313/500\n",
            "139/804 [====>.........................] - ETA: 1s - loss: 0.4452 - accuracy: 0.7830\n",
            "Epoch 00313: saving model to checkpoints/weights.313.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4502 - accuracy: 0.7785\n",
            "Epoch 314/500\n",
            "323/804 [===========>..................] - ETA: 1s - loss: 0.4525 - accuracy: 0.7779\n",
            "Epoch 00314: saving model to checkpoints/weights.314.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4505 - accuracy: 0.7788\n",
            "Epoch 315/500\n",
            "534/804 [==================>...........] - ETA: 0s - loss: 0.4533 - accuracy: 0.7742\n",
            "Epoch 00315: saving model to checkpoints/weights.315.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4506 - accuracy: 0.7790\n",
            "Epoch 316/500\n",
            "729/804 [==========================>...] - ETA: 0s - loss: 0.4508 - accuracy: 0.7785\n",
            "Epoch 00316: saving model to checkpoints/weights.316.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4507 - accuracy: 0.7787\n",
            "Epoch 317/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4506 - accuracy: 0.7787\n",
            "Epoch 318/500\n",
            "112/804 [===>..........................] - ETA: 1s - loss: 0.4420 - accuracy: 0.7829\n",
            "Epoch 00318: saving model to checkpoints/weights.318.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4507 - accuracy: 0.7795\n",
            "Epoch 319/500\n",
            "312/804 [==========>...................] - ETA: 1s - loss: 0.4454 - accuracy: 0.7827\n",
            "Epoch 00319: saving model to checkpoints/weights.319.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4504 - accuracy: 0.7780\n",
            "Epoch 320/500\n",
            "501/804 [=================>............] - ETA: 0s - loss: 0.4538 - accuracy: 0.7759\n",
            "Epoch 00320: saving model to checkpoints/weights.320.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4508 - accuracy: 0.7791\n",
            "Epoch 321/500\n",
            "719/804 [=========================>....] - ETA: 0s - loss: 0.4474 - accuracy: 0.7800\n",
            "Epoch 00321: saving model to checkpoints/weights.321.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4514 - accuracy: 0.7781\n",
            "Epoch 322/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4505 - accuracy: 0.7788\n",
            "Epoch 323/500\n",
            "100/804 [==>...........................] - ETA: 1s - loss: 0.4367 - accuracy: 0.7919\n",
            "Epoch 00323: saving model to checkpoints/weights.323.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4520 - accuracy: 0.7793\n",
            "Epoch 324/500\n",
            "295/804 [==========>...................] - ETA: 1s - loss: 0.4514 - accuracy: 0.7776\n",
            "Epoch 00324: saving model to checkpoints/weights.324.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4509 - accuracy: 0.7787\n",
            "Epoch 325/500\n",
            "498/804 [=================>............] - ETA: 0s - loss: 0.4521 - accuracy: 0.7767\n",
            "Epoch 00325: saving model to checkpoints/weights.325.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4510 - accuracy: 0.7791\n",
            "Epoch 326/500\n",
            "692/804 [========================>.....] - ETA: 0s - loss: 0.4501 - accuracy: 0.7790\n",
            "Epoch 00326: saving model to checkpoints/weights.326.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4532 - accuracy: 0.7787\n",
            "Epoch 327/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4509 - accuracy: 0.7789\n",
            "Epoch 328/500\n",
            " 89/804 [==>...........................] - ETA: 1s - loss: 0.4466 - accuracy: 0.7830\n",
            "Epoch 00328: saving model to checkpoints/weights.328.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4512 - accuracy: 0.7781\n",
            "Epoch 329/500\n",
            "280/804 [=========>....................] - ETA: 1s - loss: 0.4522 - accuracy: 0.7801\n",
            "Epoch 00329: saving model to checkpoints/weights.329.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4512 - accuracy: 0.7782\n",
            "Epoch 330/500\n",
            "483/804 [=================>............] - ETA: 0s - loss: 0.4497 - accuracy: 0.7808\n",
            "Epoch 00330: saving model to checkpoints/weights.330.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4508 - accuracy: 0.7793\n",
            "Epoch 331/500\n",
            "678/804 [========================>.....] - ETA: 0s - loss: 0.4527 - accuracy: 0.7770\n",
            "Epoch 00331: saving model to checkpoints/weights.331.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4503 - accuracy: 0.7792\n",
            "Epoch 332/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4516 - accuracy: 0.7792\n",
            "Epoch 333/500\n",
            " 66/804 [=>............................] - ETA: 1s - loss: 0.4514 - accuracy: 0.7789\n",
            "Epoch 00333: saving model to checkpoints/weights.333.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4504 - accuracy: 0.7787\n",
            "Epoch 334/500\n",
            "256/804 [========>.....................] - ETA: 1s - loss: 0.4554 - accuracy: 0.7754\n",
            "Epoch 00334: saving model to checkpoints/weights.334.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4499 - accuracy: 0.7786\n",
            "Epoch 335/500\n",
            "449/804 [===============>..............] - ETA: 0s - loss: 0.4483 - accuracy: 0.7816\n",
            "Epoch 00335: saving model to checkpoints/weights.335.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4509 - accuracy: 0.7790\n",
            "Epoch 336/500\n",
            "643/804 [======================>.......] - ETA: 0s - loss: 0.4546 - accuracy: 0.7770\n",
            "Epoch 00336: saving model to checkpoints/weights.336.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4524 - accuracy: 0.7787\n",
            "Epoch 337/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4540 - accuracy: 0.7787\n",
            "Epoch 338/500\n",
            " 46/804 [>.............................] - ETA: 1s - loss: 0.4374 - accuracy: 0.7928\n",
            "Epoch 00338: saving model to checkpoints/weights.338.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4503 - accuracy: 0.7793\n",
            "Epoch 339/500\n",
            "233/804 [=======>......................] - ETA: 1s - loss: 0.4448 - accuracy: 0.7815\n",
            "Epoch 00339: saving model to checkpoints/weights.339.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4493 - accuracy: 0.7789\n",
            "Epoch 340/500\n",
            "435/804 [===============>..............] - ETA: 0s - loss: 0.4471 - accuracy: 0.7824\n",
            "Epoch 00340: saving model to checkpoints/weights.340.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4502 - accuracy: 0.7790\n",
            "Epoch 341/500\n",
            "634/804 [======================>.......] - ETA: 0s - loss: 0.4505 - accuracy: 0.7789\n",
            "Epoch 00341: saving model to checkpoints/weights.341.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4508 - accuracy: 0.7785\n",
            "Epoch 342/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4500 - accuracy: 0.7789\n",
            "Epoch 343/500\n",
            " 21/804 [..............................] - ETA: 1s - loss: 0.4610 - accuracy: 0.7783\n",
            "Epoch 00343: saving model to checkpoints/weights.343.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4504 - accuracy: 0.7790\n",
            "Epoch 344/500\n",
            "214/804 [======>.......................] - ETA: 1s - loss: 0.4440 - accuracy: 0.7850\n",
            "Epoch 00344: saving model to checkpoints/weights.344.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4508 - accuracy: 0.7781\n",
            "Epoch 345/500\n",
            "399/804 [=============>................] - ETA: 0s - loss: 0.4390 - accuracy: 0.7890\n",
            "Epoch 00345: saving model to checkpoints/weights.345.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4504 - accuracy: 0.7797\n",
            "Epoch 346/500\n",
            "617/804 [======================>.......] - ETA: 0s - loss: 0.4508 - accuracy: 0.7785\n",
            "Epoch 00346: saving model to checkpoints/weights.346.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4516 - accuracy: 0.7787\n",
            "Epoch 347/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4499 - accuracy: 0.7792\n",
            "Epoch 348/500\n",
            "  1/804 [..............................] - ETA: 4s - loss: 0.3505 - accuracy: 0.9375\n",
            "Epoch 00348: saving model to checkpoints/weights.348.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4518 - accuracy: 0.7782\n",
            "Epoch 349/500\n",
            "198/804 [======>.......................] - ETA: 1s - loss: 0.4556 - accuracy: 0.7743\n",
            "Epoch 00349: saving model to checkpoints/weights.349.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4505 - accuracy: 0.7786\n",
            "Epoch 350/500\n",
            "388/804 [=============>................] - ETA: 0s - loss: 0.4429 - accuracy: 0.7834\n",
            "Epoch 00350: saving model to checkpoints/weights.350.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4497 - accuracy: 0.7785\n",
            "Epoch 351/500\n",
            "585/804 [====================>.........] - ETA: 0s - loss: 0.4495 - accuracy: 0.7813\n",
            "Epoch 00351: saving model to checkpoints/weights.351.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4503 - accuracy: 0.7789\n",
            "Epoch 352/500\n",
            "789/804 [============================>.] - ETA: 0s - loss: 0.4495 - accuracy: 0.7783\n",
            "Epoch 00352: saving model to checkpoints/weights.352.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4501 - accuracy: 0.7781\n",
            "Epoch 353/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4502 - accuracy: 0.7787\n",
            "Epoch 354/500\n",
            "179/804 [=====>........................] - ETA: 1s - loss: 0.4472 - accuracy: 0.7814\n",
            "Epoch 00354: saving model to checkpoints/weights.354.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4509 - accuracy: 0.7789\n",
            "Epoch 355/500\n",
            "384/804 [=============>................] - ETA: 0s - loss: 0.4459 - accuracy: 0.7789\n",
            "Epoch 00355: saving model to checkpoints/weights.355.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4501 - accuracy: 0.7795\n",
            "Epoch 356/500\n",
            "579/804 [====================>.........] - ETA: 0s - loss: 0.4472 - accuracy: 0.7822\n",
            "Epoch 00356: saving model to checkpoints/weights.356.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4507 - accuracy: 0.7789\n",
            "Epoch 357/500\n",
            "754/804 [===========================>..] - ETA: 0s - loss: 0.4497 - accuracy: 0.7788\n",
            "Epoch 00357: saving model to checkpoints/weights.357.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4505 - accuracy: 0.7782\n",
            "Epoch 358/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4506 - accuracy: 0.7789\n",
            "Epoch 359/500\n",
            "157/804 [====>.........................] - ETA: 1s - loss: 0.4569 - accuracy: 0.7743\n",
            "Epoch 00359: saving model to checkpoints/weights.359.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4504 - accuracy: 0.7781\n",
            "Epoch 360/500\n",
            "361/804 [============>.................] - ETA: 1s - loss: 0.4503 - accuracy: 0.7782\n",
            "Epoch 00360: saving model to checkpoints/weights.360.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4504 - accuracy: 0.7795\n",
            "Epoch 361/500\n",
            "554/804 [===================>..........] - ETA: 0s - loss: 0.4487 - accuracy: 0.7793\n",
            "Epoch 00361: saving model to checkpoints/weights.361.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4504 - accuracy: 0.7786\n",
            "Epoch 362/500\n",
            "747/804 [==========================>...] - ETA: 0s - loss: 0.4539 - accuracy: 0.7788\n",
            "Epoch 00362: saving model to checkpoints/weights.362.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4543 - accuracy: 0.7789\n",
            "Epoch 363/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4632 - accuracy: 0.7779\n",
            "Epoch 364/500\n",
            "130/804 [===>..........................] - ETA: 1s - loss: 0.4499 - accuracy: 0.7796\n",
            "Epoch 00364: saving model to checkpoints/weights.364.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4497 - accuracy: 0.7795\n",
            "Epoch 365/500\n",
            "337/804 [===========>..................] - ETA: 1s - loss: 0.4467 - accuracy: 0.7828\n",
            "Epoch 00365: saving model to checkpoints/weights.365.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4497 - accuracy: 0.7791\n",
            "Epoch 366/500\n",
            "529/804 [==================>...........] - ETA: 0s - loss: 0.4470 - accuracy: 0.7816\n",
            "Epoch 00366: saving model to checkpoints/weights.366.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4496 - accuracy: 0.7796\n",
            "Epoch 367/500\n",
            "730/804 [==========================>...] - ETA: 0s - loss: 0.4489 - accuracy: 0.7791\n",
            "Epoch 00367: saving model to checkpoints/weights.367.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4496 - accuracy: 0.7783\n",
            "Epoch 368/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4500 - accuracy: 0.7791\n",
            "Epoch 369/500\n",
            "111/804 [===>..........................] - ETA: 1s - loss: 0.4463 - accuracy: 0.7804\n",
            "Epoch 00369: saving model to checkpoints/weights.369.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4499 - accuracy: 0.7793\n",
            "Epoch 370/500\n",
            "313/804 [==========>...................] - ETA: 1s - loss: 0.4469 - accuracy: 0.7821\n",
            "Epoch 00370: saving model to checkpoints/weights.370.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4501 - accuracy: 0.7787\n",
            "Epoch 371/500\n",
            "505/804 [=================>............] - ETA: 0s - loss: 0.4543 - accuracy: 0.7753\n",
            "Epoch 00371: saving model to checkpoints/weights.371.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4503 - accuracy: 0.7794\n",
            "Epoch 372/500\n",
            "703/804 [=========================>....] - ETA: 0s - loss: 0.4486 - accuracy: 0.7810\n",
            "Epoch 00372: saving model to checkpoints/weights.372.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4504 - accuracy: 0.7791\n",
            "Epoch 373/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4531 - accuracy: 0.7789\n",
            "Epoch 374/500\n",
            " 93/804 [==>...........................] - ETA: 1s - loss: 0.4458 - accuracy: 0.7816\n",
            "Epoch 00374: saving model to checkpoints/weights.374.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4507 - accuracy: 0.7788\n",
            "Epoch 375/500\n",
            "290/804 [=========>....................] - ETA: 1s - loss: 0.4486 - accuracy: 0.7802\n",
            "Epoch 00375: saving model to checkpoints/weights.375.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4501 - accuracy: 0.7789\n",
            "Epoch 376/500\n",
            "497/804 [=================>............] - ETA: 0s - loss: 0.4487 - accuracy: 0.7794\n",
            "Epoch 00376: saving model to checkpoints/weights.376.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4501 - accuracy: 0.7787\n",
            "Epoch 377/500\n",
            "693/804 [========================>.....] - ETA: 0s - loss: 0.4505 - accuracy: 0.7773\n",
            "Epoch 00377: saving model to checkpoints/weights.377.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4496 - accuracy: 0.7783\n",
            "Epoch 378/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4505 - accuracy: 0.7792\n",
            "Epoch 379/500\n",
            " 88/804 [==>...........................] - ETA: 1s - loss: 0.4494 - accuracy: 0.7770\n",
            "Epoch 00379: saving model to checkpoints/weights.379.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4498 - accuracy: 0.7789\n",
            "Epoch 380/500\n",
            "268/804 [=========>....................] - ETA: 1s - loss: 0.4606 - accuracy: 0.7699\n",
            "Epoch 00380: saving model to checkpoints/weights.380.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4552 - accuracy: 0.7789\n",
            "Epoch 381/500\n",
            "480/804 [================>.............] - ETA: 0s - loss: 0.4506 - accuracy: 0.7815\n",
            "Epoch 00381: saving model to checkpoints/weights.381.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4516 - accuracy: 0.7793\n",
            "Epoch 382/500\n",
            "666/804 [=======================>......] - ETA: 0s - loss: 0.4496 - accuracy: 0.7797\n",
            "Epoch 00382: saving model to checkpoints/weights.382.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4508 - accuracy: 0.7787\n",
            "Epoch 383/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4501 - accuracy: 0.7783\n",
            "Epoch 384/500\n",
            " 62/804 [=>............................] - ETA: 1s - loss: 0.4431 - accuracy: 0.7848\n",
            "Epoch 00384: saving model to checkpoints/weights.384.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4501 - accuracy: 0.7783\n",
            "Epoch 385/500\n",
            "261/804 [========>.....................] - ETA: 1s - loss: 0.4498 - accuracy: 0.7787\n",
            "Epoch 00385: saving model to checkpoints/weights.385.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4506 - accuracy: 0.7783\n",
            "Epoch 386/500\n",
            "455/804 [===============>..............] - ETA: 0s - loss: 0.4476 - accuracy: 0.7807\n",
            "Epoch 00386: saving model to checkpoints/weights.386.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4500 - accuracy: 0.7785\n",
            "Epoch 387/500\n",
            "639/804 [======================>.......] - ETA: 0s - loss: 0.4501 - accuracy: 0.7807\n",
            "Epoch 00387: saving model to checkpoints/weights.387.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4504 - accuracy: 0.7790\n",
            "Epoch 388/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5211 - accuracy: 0.7783\n",
            "Epoch 389/500\n",
            " 45/804 [>.............................] - ETA: 1s - loss: 0.4676 - accuracy: 0.7757\n",
            "Epoch 00389: saving model to checkpoints/weights.389.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4533 - accuracy: 0.7787\n",
            "Epoch 390/500\n",
            "240/804 [=======>......................] - ETA: 1s - loss: 0.4564 - accuracy: 0.7732\n",
            "Epoch 00390: saving model to checkpoints/weights.390.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4493 - accuracy: 0.7788\n",
            "Epoch 391/500\n",
            "440/804 [===============>..............] - ETA: 0s - loss: 0.4505 - accuracy: 0.7814\n",
            "Epoch 00391: saving model to checkpoints/weights.391.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4494 - accuracy: 0.7790\n",
            "Epoch 392/500\n",
            "633/804 [======================>.......] - ETA: 0s - loss: 0.4496 - accuracy: 0.7792\n",
            "Epoch 00392: saving model to checkpoints/weights.392.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4496 - accuracy: 0.7795\n",
            "Epoch 393/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4494 - accuracy: 0.7796\n",
            "Epoch 394/500\n",
            " 15/804 [..............................] - ETA: 2s - loss: 0.4656 - accuracy: 0.7792\n",
            "Epoch 00394: saving model to checkpoints/weights.394.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4493 - accuracy: 0.7790\n",
            "Epoch 395/500\n",
            "220/804 [=======>......................] - ETA: 1s - loss: 0.4465 - accuracy: 0.7824\n",
            "Epoch 00395: saving model to checkpoints/weights.395.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4496 - accuracy: 0.7790\n",
            "Epoch 396/500\n",
            "417/804 [==============>...............] - ETA: 0s - loss: 0.4485 - accuracy: 0.7821\n",
            "Epoch 00396: saving model to checkpoints/weights.396.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4503 - accuracy: 0.7786\n",
            "Epoch 397/500\n",
            "602/804 [=====================>........] - ETA: 0s - loss: 0.4494 - accuracy: 0.7796\n",
            "Epoch 00397: saving model to checkpoints/weights.397.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4504 - accuracy: 0.7790\n",
            "Epoch 398/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4502 - accuracy: 0.7795\n",
            "Epoch 399/500\n",
            "  1/804 [..............................] - ETA: 2s - loss: 0.3183 - accuracy: 0.9062\n",
            "Epoch 00399: saving model to checkpoints/weights.399.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4498 - accuracy: 0.7786\n",
            "Epoch 400/500\n",
            "186/804 [=====>........................] - ETA: 1s - loss: 0.4423 - accuracy: 0.7804\n",
            "Epoch 00400: saving model to checkpoints/weights.400.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4502 - accuracy: 0.7790\n",
            "Epoch 401/500\n",
            "393/804 [=============>................] - ETA: 0s - loss: 0.4531 - accuracy: 0.7766\n",
            "Epoch 00401: saving model to checkpoints/weights.401.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4498 - accuracy: 0.7792\n",
            "Epoch 402/500\n",
            "590/804 [=====================>........] - ETA: 0s - loss: 0.4525 - accuracy: 0.7769\n",
            "Epoch 00402: saving model to checkpoints/weights.402.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4509 - accuracy: 0.7786\n",
            "Epoch 403/500\n",
            "770/804 [===========================>..] - ETA: 0s - loss: 0.4498 - accuracy: 0.7806\n",
            "Epoch 00403: saving model to checkpoints/weights.403.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4508 - accuracy: 0.7794\n",
            "Epoch 404/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4502 - accuracy: 0.7791\n",
            "Epoch 405/500\n",
            "169/804 [=====>........................] - ETA: 1s - loss: 0.4469 - accuracy: 0.7768\n",
            "Epoch 00405: saving model to checkpoints/weights.405.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4504 - accuracy: 0.7781\n",
            "Epoch 406/500\n",
            "368/804 [============>.................] - ETA: 1s - loss: 0.4499 - accuracy: 0.7801\n",
            "Epoch 00406: saving model to checkpoints/weights.406.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4498 - accuracy: 0.7794\n",
            "Epoch 407/500\n",
            "568/804 [====================>.........] - ETA: 0s - loss: 0.4507 - accuracy: 0.7805\n",
            "Epoch 00407: saving model to checkpoints/weights.407.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4505 - accuracy: 0.7792\n",
            "Epoch 408/500\n",
            "765/804 [===========================>..] - ETA: 0s - loss: 0.4511 - accuracy: 0.7791\n",
            "Epoch 00408: saving model to checkpoints/weights.408.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4507 - accuracy: 0.7792\n",
            "Epoch 409/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4524 - accuracy: 0.7788\n",
            "Epoch 410/500\n",
            "152/804 [====>.........................] - ETA: 1s - loss: 0.4423 - accuracy: 0.7858\n",
            "Epoch 00410: saving model to checkpoints/weights.410.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4507 - accuracy: 0.7789\n",
            "Epoch 411/500\n",
            "353/804 [============>.................] - ETA: 1s - loss: 0.4495 - accuracy: 0.7788\n",
            "Epoch 00411: saving model to checkpoints/weights.411.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4506 - accuracy: 0.7791\n",
            "Epoch 412/500\n",
            "552/804 [===================>..........] - ETA: 0s - loss: 0.4509 - accuracy: 0.7786\n",
            "Epoch 00412: saving model to checkpoints/weights.412.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4506 - accuracy: 0.7789\n",
            "Epoch 413/500\n",
            "749/804 [==========================>...] - ETA: 0s - loss: 0.4913 - accuracy: 0.7794\n",
            "Epoch 00413: saving model to checkpoints/weights.413.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4882 - accuracy: 0.7791\n",
            "Epoch 414/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4567 - accuracy: 0.7788\n",
            "Epoch 415/500\n",
            "132/804 [===>..........................] - ETA: 1s - loss: 0.4536 - accuracy: 0.7756\n",
            "Epoch 00415: saving model to checkpoints/weights.415.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4513 - accuracy: 0.7792\n",
            "Epoch 416/500\n",
            "318/804 [==========>...................] - ETA: 1s - loss: 0.4494 - accuracy: 0.7775\n",
            "Epoch 00416: saving model to checkpoints/weights.416.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4490 - accuracy: 0.7794\n",
            "Epoch 417/500\n",
            "517/804 [==================>...........] - ETA: 0s - loss: 0.4530 - accuracy: 0.7767\n",
            "Epoch 00417: saving model to checkpoints/weights.417.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4492 - accuracy: 0.7793\n",
            "Epoch 418/500\n",
            "730/804 [==========================>...] - ETA: 0s - loss: 0.4502 - accuracy: 0.7785\n",
            "Epoch 00418: saving model to checkpoints/weights.418.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4496 - accuracy: 0.7790\n",
            "Epoch 419/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4497 - accuracy: 0.7795\n",
            "Epoch 420/500\n",
            "112/804 [===>..........................] - ETA: 1s - loss: 0.4430 - accuracy: 0.7877\n",
            "Epoch 00420: saving model to checkpoints/weights.420.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4498 - accuracy: 0.7785\n",
            "Epoch 421/500\n",
            "309/804 [==========>...................] - ETA: 1s - loss: 0.4437 - accuracy: 0.7839\n",
            "Epoch 00421: saving model to checkpoints/weights.421.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4492 - accuracy: 0.7792\n",
            "Epoch 422/500\n",
            "515/804 [==================>...........] - ETA: 0s - loss: 0.4481 - accuracy: 0.7800\n",
            "Epoch 00422: saving model to checkpoints/weights.422.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4497 - accuracy: 0.7784\n",
            "Epoch 423/500\n",
            "690/804 [========================>.....] - ETA: 0s - loss: 0.4509 - accuracy: 0.7777\n",
            "Epoch 00423: saving model to checkpoints/weights.423.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4501 - accuracy: 0.7787\n",
            "Epoch 424/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4508 - accuracy: 0.7794\n",
            "Epoch 425/500\n",
            " 84/804 [==>...........................] - ETA: 1s - loss: 0.4481 - accuracy: 0.7757\n",
            "Epoch 00425: saving model to checkpoints/weights.425.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4503 - accuracy: 0.7784\n",
            "Epoch 426/500\n",
            "282/804 [=========>....................] - ETA: 1s - loss: 0.4444 - accuracy: 0.7870\n",
            "Epoch 00426: saving model to checkpoints/weights.426.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4500 - accuracy: 0.7796\n",
            "Epoch 427/500\n",
            "490/804 [=================>............] - ETA: 0s - loss: 0.4473 - accuracy: 0.7809\n",
            "Epoch 00427: saving model to checkpoints/weights.427.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4499 - accuracy: 0.7785\n",
            "Epoch 428/500\n",
            "692/804 [========================>.....] - ETA: 0s - loss: 0.4538 - accuracy: 0.7771\n",
            "Epoch 00428: saving model to checkpoints/weights.428.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4527 - accuracy: 0.7786\n",
            "Epoch 429/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4513 - accuracy: 0.7794\n",
            "Epoch 430/500\n",
            " 73/804 [=>............................] - ETA: 2s - loss: 0.4697 - accuracy: 0.7748\n",
            "Epoch 00430: saving model to checkpoints/weights.430.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4509 - accuracy: 0.7791\n",
            "Epoch 431/500\n",
            "275/804 [=========>....................] - ETA: 1s - loss: 0.4588 - accuracy: 0.7681\n",
            "Epoch 00431: saving model to checkpoints/weights.431.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4498 - accuracy: 0.7795\n",
            "Epoch 432/500\n",
            "464/804 [================>.............] - ETA: 0s - loss: 0.4461 - accuracy: 0.7813\n",
            "Epoch 00432: saving model to checkpoints/weights.432.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4495 - accuracy: 0.7797\n",
            "Epoch 433/500\n",
            "660/804 [=======================>......] - ETA: 0s - loss: 0.4499 - accuracy: 0.7783\n",
            "Epoch 00433: saving model to checkpoints/weights.433.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4497 - accuracy: 0.7789\n",
            "Epoch 434/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4505 - accuracy: 0.7791\n",
            "Epoch 435/500\n",
            " 64/804 [=>............................] - ETA: 1s - loss: 0.4513 - accuracy: 0.7759\n",
            "Epoch 00435: saving model to checkpoints/weights.435.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4499 - accuracy: 0.7786\n",
            "Epoch 436/500\n",
            "244/804 [========>.....................] - ETA: 1s - loss: 0.4506 - accuracy: 0.7769\n",
            "Epoch 00436: saving model to checkpoints/weights.436.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4499 - accuracy: 0.7785\n",
            "Epoch 437/500\n",
            "448/804 [===============>..............] - ETA: 0s - loss: 0.4509 - accuracy: 0.7806\n",
            "Epoch 00437: saving model to checkpoints/weights.437.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4511 - accuracy: 0.7787\n",
            "Epoch 438/500\n",
            "645/804 [=======================>......] - ETA: 0s - loss: 0.4564 - accuracy: 0.7776\n",
            "Epoch 00438: saving model to checkpoints/weights.438.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4538 - accuracy: 0.7790\n",
            "Epoch 439/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4504 - accuracy: 0.7786\n",
            "Epoch 440/500\n",
            " 21/804 [..............................] - ETA: 1s - loss: 0.4728 - accuracy: 0.7753\n",
            "Epoch 00440: saving model to checkpoints/weights.440.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4504 - accuracy: 0.7794\n",
            "Epoch 441/500\n",
            "233/804 [=======>......................] - ETA: 1s - loss: 0.4513 - accuracy: 0.7792\n",
            "Epoch 00441: saving model to checkpoints/weights.441.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4502 - accuracy: 0.7794\n",
            "Epoch 442/500\n",
            "433/804 [===============>..............] - ETA: 0s - loss: 0.4500 - accuracy: 0.7807\n",
            "Epoch 00442: saving model to checkpoints/weights.442.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4501 - accuracy: 0.7790\n",
            "Epoch 443/500\n",
            "628/804 [======================>.......] - ETA: 0s - loss: 0.4508 - accuracy: 0.7786\n",
            "Epoch 00443: saving model to checkpoints/weights.443.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4499 - accuracy: 0.7792\n",
            "Epoch 444/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4498 - accuracy: 0.7789\n",
            "Epoch 445/500\n",
            " 20/804 [..............................] - ETA: 2s - loss: 0.4444 - accuracy: 0.7828\n",
            "Epoch 00445: saving model to checkpoints/weights.445.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4527 - accuracy: 0.7783\n",
            "Epoch 446/500\n",
            "220/804 [=======>......................] - ETA: 1s - loss: 0.4405 - accuracy: 0.7858\n",
            "Epoch 00446: saving model to checkpoints/weights.446.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4522 - accuracy: 0.7790\n",
            "Epoch 447/500\n",
            "415/804 [==============>...............] - ETA: 0s - loss: 0.4523 - accuracy: 0.7741\n",
            "Epoch 00447: saving model to checkpoints/weights.447.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4498 - accuracy: 0.7786\n",
            "Epoch 448/500\n",
            "593/804 [=====================>........] - ETA: 0s - loss: 0.4489 - accuracy: 0.7796\n",
            "Epoch 00448: saving model to checkpoints/weights.448.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4500 - accuracy: 0.7793\n",
            "Epoch 449/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4497 - accuracy: 0.7792\n",
            "Epoch 450/500\n",
            "  1/804 [..............................] - ETA: 7s - loss: 0.3983 - accuracy: 0.8438\n",
            "Epoch 00450: saving model to checkpoints/weights.450.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4499 - accuracy: 0.7790\n",
            "Epoch 451/500\n",
            "185/804 [=====>........................] - ETA: 1s - loss: 0.4524 - accuracy: 0.7753\n",
            "Epoch 00451: saving model to checkpoints/weights.451.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4511 - accuracy: 0.7788\n",
            "Epoch 452/500\n",
            "392/804 [=============>................] - ETA: 0s - loss: 0.4489 - accuracy: 0.7789\n",
            "Epoch 00452: saving model to checkpoints/weights.452.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4503 - accuracy: 0.7791\n",
            "Epoch 453/500\n",
            "574/804 [====================>.........] - ETA: 0s - loss: 0.4516 - accuracy: 0.7783\n",
            "Epoch 00453: saving model to checkpoints/weights.453.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4507 - accuracy: 0.7792\n",
            "Epoch 454/500\n",
            "772/804 [===========================>..] - ETA: 0s - loss: 0.4496 - accuracy: 0.7801\n",
            "Epoch 00454: saving model to checkpoints/weights.454.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4504 - accuracy: 0.7797\n",
            "Epoch 455/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4504 - accuracy: 0.7791\n",
            "Epoch 456/500\n",
            "174/804 [=====>........................] - ETA: 1s - loss: 0.4403 - accuracy: 0.7834\n",
            "Epoch 00456: saving model to checkpoints/weights.456.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4498 - accuracy: 0.7790\n",
            "Epoch 457/500\n",
            "359/804 [============>.................] - ETA: 1s - loss: 0.4485 - accuracy: 0.7799\n",
            "Epoch 00457: saving model to checkpoints/weights.457.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4503 - accuracy: 0.7790\n",
            "Epoch 458/500\n",
            "558/804 [===================>..........] - ETA: 0s - loss: 0.4498 - accuracy: 0.7781\n",
            "Epoch 00458: saving model to checkpoints/weights.458.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4502 - accuracy: 0.7787\n",
            "Epoch 459/500\n",
            "751/804 [===========================>..] - ETA: 0s - loss: 0.4502 - accuracy: 0.7793\n",
            "Epoch 00459: saving model to checkpoints/weights.459.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4503 - accuracy: 0.7789\n",
            "Epoch 460/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4504 - accuracy: 0.7789\n",
            "Epoch 461/500\n",
            "147/804 [====>.........................] - ETA: 1s - loss: 0.4515 - accuracy: 0.7804\n",
            "Epoch 00461: saving model to checkpoints/weights.461.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4532 - accuracy: 0.7785\n",
            "Epoch 462/500\n",
            "339/804 [===========>..................] - ETA: 1s - loss: 0.4561 - accuracy: 0.7793\n",
            "Epoch 00462: saving model to checkpoints/weights.462.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4541 - accuracy: 0.7792\n",
            "Epoch 463/500\n",
            "549/804 [===================>..........] - ETA: 0s - loss: 0.4498 - accuracy: 0.7809\n",
            "Epoch 00463: saving model to checkpoints/weights.463.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4500 - accuracy: 0.7793\n",
            "Epoch 464/500\n",
            "727/804 [==========================>...] - ETA: 0s - loss: 0.4496 - accuracy: 0.7785\n",
            "Epoch 00464: saving model to checkpoints/weights.464.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4504 - accuracy: 0.7791\n",
            "Epoch 465/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4498 - accuracy: 0.7787\n",
            "Epoch 466/500\n",
            "127/804 [===>..........................] - ETA: 1s - loss: 0.4575 - accuracy: 0.7704\n",
            "Epoch 00466: saving model to checkpoints/weights.466.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4496 - accuracy: 0.7790\n",
            "Epoch 467/500\n",
            "334/804 [===========>..................] - ETA: 1s - loss: 0.4462 - accuracy: 0.7817\n",
            "Epoch 00467: saving model to checkpoints/weights.467.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4500 - accuracy: 0.7795\n",
            "Epoch 468/500\n",
            "523/804 [==================>...........] - ETA: 0s - loss: 0.4500 - accuracy: 0.7788\n",
            "Epoch 00468: saving model to checkpoints/weights.468.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4499 - accuracy: 0.7788\n",
            "Epoch 469/500\n",
            "715/804 [=========================>....] - ETA: 0s - loss: 0.4515 - accuracy: 0.7771\n",
            "Epoch 00469: saving model to checkpoints/weights.469.hdf5\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4497 - accuracy: 0.7787\n",
            "Epoch 470/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4677 - accuracy: 0.7783\n",
            "Epoch 471/500\n",
            "104/804 [==>...........................] - ETA: 1s - loss: 0.6691 - accuracy: 0.7740\n",
            "Epoch 00471: saving model to checkpoints/weights.471.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4812 - accuracy: 0.7788\n",
            "Epoch 472/500\n",
            "299/804 [==========>...................] - ETA: 1s - loss: 0.4496 - accuracy: 0.7769\n",
            "Epoch 00472: saving model to checkpoints/weights.472.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4501 - accuracy: 0.7787\n",
            "Epoch 473/500\n",
            "509/804 [=================>............] - ETA: 0s - loss: 0.4458 - accuracy: 0.7794\n",
            "Epoch 00473: saving model to checkpoints/weights.473.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4495 - accuracy: 0.7791\n",
            "Epoch 474/500\n",
            "700/804 [=========================>....] - ETA: 0s - loss: 0.4493 - accuracy: 0.7795\n",
            "Epoch 00474: saving model to checkpoints/weights.474.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4491 - accuracy: 0.7796\n",
            "Epoch 475/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4493 - accuracy: 0.7787\n",
            "Epoch 476/500\n",
            " 85/804 [==>...........................] - ETA: 1s - loss: 0.4426 - accuracy: 0.7886\n",
            "Epoch 00476: saving model to checkpoints/weights.476.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4493 - accuracy: 0.7790\n",
            "Epoch 477/500\n",
            "289/804 [=========>....................] - ETA: 1s - loss: 0.4466 - accuracy: 0.7840\n",
            "Epoch 00477: saving model to checkpoints/weights.477.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4498 - accuracy: 0.7785\n",
            "Epoch 478/500\n",
            "470/804 [================>.............] - ETA: 0s - loss: 0.4488 - accuracy: 0.7801\n",
            "Epoch 00478: saving model to checkpoints/weights.478.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4497 - accuracy: 0.7790\n",
            "Epoch 479/500\n",
            "677/804 [========================>.....] - ETA: 0s - loss: 0.4517 - accuracy: 0.7777\n",
            "Epoch 00479: saving model to checkpoints/weights.479.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4494 - accuracy: 0.7793\n",
            "Epoch 480/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4495 - accuracy: 0.7790\n",
            "Epoch 481/500\n",
            " 75/804 [=>............................] - ETA: 2s - loss: 0.4378 - accuracy: 0.7837\n",
            "Epoch 00481: saving model to checkpoints/weights.481.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4497 - accuracy: 0.7785\n",
            "Epoch 482/500\n",
            "263/804 [========>.....................] - ETA: 1s - loss: 0.4417 - accuracy: 0.7887\n",
            "Epoch 00482: saving model to checkpoints/weights.482.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4514 - accuracy: 0.7789\n",
            "Epoch 483/500\n",
            "462/804 [================>.............] - ETA: 0s - loss: 0.4528 - accuracy: 0.7790\n",
            "Epoch 00483: saving model to checkpoints/weights.483.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4502 - accuracy: 0.7793\n",
            "Epoch 484/500\n",
            "657/804 [=======================>......] - ETA: 0s - loss: 0.4490 - accuracy: 0.7797\n",
            "Epoch 00484: saving model to checkpoints/weights.484.hdf5\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4497 - accuracy: 0.7785\n",
            "Epoch 485/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4499 - accuracy: 0.7789\n",
            "Epoch 486/500\n",
            " 40/804 [>.............................] - ETA: 2s - loss: 0.4290 - accuracy: 0.7805\n",
            "Epoch 00486: saving model to checkpoints/weights.486.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4497 - accuracy: 0.7785\n",
            "Epoch 487/500\n",
            "248/804 [========>.....................] - ETA: 1s - loss: 0.4434 - accuracy: 0.7823\n",
            "Epoch 00487: saving model to checkpoints/weights.487.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4566 - accuracy: 0.7789\n",
            "Epoch 488/500\n",
            "443/804 [===============>..............] - ETA: 0s - loss: 0.4534 - accuracy: 0.7789\n",
            "Epoch 00488: saving model to checkpoints/weights.488.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4507 - accuracy: 0.7795\n",
            "Epoch 489/500\n",
            "628/804 [======================>.......] - ETA: 0s - loss: 0.4533 - accuracy: 0.7773\n",
            "Epoch 00489: saving model to checkpoints/weights.489.hdf5\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4519 - accuracy: 0.7781\n",
            "Epoch 490/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4498 - accuracy: 0.7792\n",
            "Epoch 491/500\n",
            " 40/804 [>.............................] - ETA: 1s - loss: 0.4322 - accuracy: 0.7945\n",
            "Epoch 00491: saving model to checkpoints/weights.491.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4503 - accuracy: 0.7790\n",
            "Epoch 492/500\n",
            "230/804 [=======>......................] - ETA: 1s - loss: 0.4570 - accuracy: 0.7793\n",
            "Epoch 00492: saving model to checkpoints/weights.492.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4516 - accuracy: 0.7787\n",
            "Epoch 493/500\n",
            "428/804 [==============>...............] - ETA: 0s - loss: 0.4502 - accuracy: 0.7796\n",
            "Epoch 00493: saving model to checkpoints/weights.493.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4505 - accuracy: 0.7787\n",
            "Epoch 494/500\n",
            "606/804 [=====================>........] - ETA: 0s - loss: 0.4467 - accuracy: 0.7803\n",
            "Epoch 00494: saving model to checkpoints/weights.494.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4503 - accuracy: 0.7797\n",
            "Epoch 495/500\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4498 - accuracy: 0.7794\n",
            "Epoch 496/500\n",
            " 19/804 [..............................] - ETA: 2s - loss: 0.4823 - accuracy: 0.7500 \n",
            "Epoch 00496: saving model to checkpoints/weights.496.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4498 - accuracy: 0.7792\n",
            "Epoch 497/500\n",
            "203/804 [======>.......................] - ETA: 1s - loss: 0.4474 - accuracy: 0.7802\n",
            "Epoch 00497: saving model to checkpoints/weights.497.hdf5\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4519 - accuracy: 0.7789\n",
            "Epoch 498/500\n",
            "401/804 [=============>................] - ETA: 0s - loss: 0.4503 - accuracy: 0.7788\n",
            "Epoch 00498: saving model to checkpoints/weights.498.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4498 - accuracy: 0.7788\n",
            "Epoch 499/500\n",
            "590/804 [=====================>........] - ETA: 0s - loss: 0.4499 - accuracy: 0.7792\n",
            "Epoch 00499: saving model to checkpoints/weights.499.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4498 - accuracy: 0.7795\n",
            "Epoch 500/500\n",
            "804/804 [==============================] - ETA: 0s - loss: 0.4499 - accuracy: 0.7791\n",
            "Epoch 00500: saving model to checkpoints/weights.500.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4499 - accuracy: 0.7791\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03X2kKILylJL"
      },
      "source": [
        ""
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xc1xpLRhylWM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc56e0eb-01d5-413d-f3bb-c72d676729c9"
      },
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 - 0s - loss: 0.6673 - accuracy: 0.7613\n",
            "Loss: 0.667323648929596, Accuracy: 0.7612828016281128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9NjlhxSylib"
      },
      "source": [
        "# Export our model to HDF5 file\n",
        "nn.save(\"AlphabetSoupCharity_Optimized_del3.h5\")"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYAUWqS9ylvW"
      },
      "source": [
        ""
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQYnv9j4yUZN"
      },
      "source": [
        ""
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMcRfZkyyUc2"
      },
      "source": [
        ""
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygKLs8TbyUf5"
      },
      "source": [
        ""
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELsttQ82yUjD"
      },
      "source": [
        ""
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1n_C-wFUyUmy"
      },
      "source": [
        ""
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PklhPArLty59"
      },
      "source": [
        ""
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oA6nqitQ5eR6"
      },
      "source": [
        ""
      ],
      "execution_count": 38,
      "outputs": []
    }
  ]
}